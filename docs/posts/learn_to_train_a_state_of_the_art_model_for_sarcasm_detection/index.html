<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Learn to Train a State-of-the-Art Model for Sarcasm Detection | News @ machinelearning.sg</title><meta name=keywords content="Natural Language Processing,Deep Learning,Machine Learning,GPU,Source Code,PyTorch,Sarcasm Detection,Jupyter Notebook,Colab"><meta name=description content="tl;dr A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a free Jupyter Notebook in the cloud.
 Sooo Impressive Sarcasm Detection Model on Tweets Recently Venture Beat published (and Communications of the ACM referenced)
a news article titled &ldquo;AI researchers made a sarcasm detection model and it‚Äôs sooo impressive&rdquo; which detailed how researchers from China had come up with a &ldquo;sarcasm detection AI&rdquo; that &ldquo;achieved state-of-the-art performance on a dataset drawn from Twitter&rdquo;."><meta name=author content="Eugene"><link rel=canonical href=https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/><link href=https://news.machinelearning.sg/assets/css/stylesheet.min.62447981861ad5bc7761e73be43801fe136a2aaaa8b7afd18ce582c358716848.css integrity="sha256-YkR5gYYa1bx3Yec75DgB/hNqKqqot6/RjOWCw1hxaEg=" rel="preload stylesheet" as=style><link rel=icon href=https://news.machinelearning.sg/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://news.machinelearning.sg/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://news.machinelearning.sg/favicon-32x32.png><link rel=apple-touch-icon href=https://news.machinelearning.sg/apple-touch-icon.png><link rel=mask-icon href=https://news.machinelearning.sg/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.79.0"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-185405110-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Learn to Train a State-of-the-Art Model for Sarcasm Detection"><meta property="og:description" content="tl;dr A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a free Jupyter Notebook in the cloud.
 Sooo Impressive Sarcasm Detection Model on Tweets Recently Venture Beat published (and Communications of the ACM referenced)
a news article titled &ldquo;AI researchers made a sarcasm detection model and it‚Äôs sooo impressive&rdquo; which detailed how researchers from China had come up with a &ldquo;sarcasm detection AI&rdquo; that &ldquo;achieved state-of-the-art performance on a dataset drawn from Twitter&rdquo;."><meta property="og:type" content="article"><meta property="og:url" content="https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/"><meta property="og:image" content="https://news.machinelearning.sg/sarcasm_detection.png"><meta property="article:published_time" content="2020-12-22T09:00:00+08:00"><meta property="article:modified_time" content="2020-12-22T09:00:00+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://news.machinelearning.sg/sarcasm_detection.png"><meta name=twitter:title content="Learn to Train a State-of-the-Art Model for Sarcasm Detection"><meta name=twitter:description content="tl;dr A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a free Jupyter Notebook in the cloud.
 Sooo Impressive Sarcasm Detection Model on Tweets Recently Venture Beat published (and Communications of the ACM referenced)
a news article titled &ldquo;AI researchers made a sarcasm detection model and it‚Äôs sooo impressive&rdquo; which detailed how researchers from China had come up with a &ldquo;sarcasm detection AI&rdquo; that &ldquo;achieved state-of-the-art performance on a dataset drawn from Twitter&rdquo;."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Learn to Train a State-of-the-Art Model for Sarcasm Detection","name":"Learn to Train a State-of-the-Art Model for Sarcasm Detection","description":"tl;dr A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a free Jupyter Notebook in the cloud.\n Sooo Impressive Sarcasm Detection Model ‚Ä¶","keywords":["Natural Language Processing","Deep Learning","Machine Learning","GPU","Source Code","PyTorch","Sarcasm Detection","Jupyter Notebook","Colab"],"articleBody":" tl;dr A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a free Jupyter Notebook in the cloud.\n Sooo Impressive Sarcasm Detection Model on Tweets Recently Venture Beat published (and Communications of the ACM referenced)\na news article titled ‚ÄúAI researchers made a sarcasm detection model and it‚Äôs sooo impressive‚Äù which detailed how researchers from China had come up with a ‚Äúsarcasm detection AI‚Äù that ‚Äúachieved state-of-the-art performance on a dataset drawn from Twitter‚Äù.\nWhat is interesting about the AI model was that it used multimodal learning to combine text and imagery from the tweets to do this sarcasm detection, ‚Äúsince both are often needed to understand whether a person is being sarcastic‚Äù.\n  Heatmap Visualization of Attention Focus on Images of Sarcastic Tweets. Retrieved from the official paper.   The premise and findings like the above figure were interesting and kudos to the team behind the paper.\nIn this step-by-step practical, we will learn to train a model that has better performance (F1-score) than this state-of-the-art model on the same dataset while using only the text from the tweets.\nPractical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.\nIn this step-by-step practical, we will learn to train a model that has better performance (F1-score) than the state-of-the-art model.\nHit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough. \nContinue on if you prefer reading the code here.\nSarcasm Detection on Twitter Data \nNotebook to train a BERT-based (RoBERTa) model to perform sarcasm detection. The dataset used is a collection of (more than 20,000) tweets with binary labels: not sarcastic or sarcastic from the paper by Cai et al. (2019). The trained model beats the state-of-the-art at this time (Dec 2020). The current state-of-the-art model on this dataset by Pan et al. (2020) uses additional information of features from hash-tags and and the image posted along with the tweet (multi-modal sarcasm detection) whereas this model uses just the textual features.\nThe notebook is structured as follows:\n Setting up the GPU Environment Getting Data Training and Testing the Model Using the Model (Running Inference)  Task Description  The goal of Sarcasm Detection is to determine whether a sentence is sarcastic or non-sarcastic. Sarcasm is a type of phenomenon with specific perlocutionary effects on the hearer, such as to break their pattern of expectation. Consequently, correct understanding of sarcasm often requires a deep understanding of multiple sources of information, including the utterance, the conversational context, and, frequently some real world facts.\n Source: Attentional Multi-Reading Sarcasm Detection\nSetting up the GPU Environment Ensure we have a GPU runtime If you‚Äôre running this notebook in Google Colab, select Runtime  Change Runtime Type from the menubar. Ensure that GPU is selected as the Hardware accelerator. This will allow us to use the GPU to train the model subsequently.\nInstall Dependencies and Restart Runtime !pip install -q transformers !pip install -q simpletransformers You might see the error ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible after installing the dependencies. This is normal and caused by the simpletransformers library.\nThe solution to this will be to reset the execution environment now. Go to the menu Runtime  Restart runtime then continue on from the next section to download and process the data.\nGetting Data Here are the functions that will allow us to download the dataset from the Github data repository of the paper by Cai et al. (2019). The function will also process the dataset so we can read it into pandas.\nimport csv import urllib.request def filtered(sentence): \"\"\"Filter function that indication if sentence should be filtered. Filtering function that is adapted from the original, more verbose, pre-processing script from the Cai et al. (2019) paper: https://github.com/headacheboy/data-of-multimodal-sarcasm-detection/blob/master/codes/loadData.py Args: sentence: A string of the sentence to be filtered. Returns: A boolean value (True or False) that indicates if a sentence should be filtered of based on the criterea by Cai et al. (2019). \"\"\" words = sentence.split() filter = ['sarcasm', 'sarcastic', 'reposting', '', 'joke', 'humour', 'humor', 'jokes', 'irony', 'ironic', 'exgag'] for filtered_word in filter: if filtered_word in words: return True return False def download_and_clean(url, output_file, text_index, labels_index, to_filter=False): \"\"\"Download and pre-process the paper's tweet dataset. Downloads the dataset from a url (github repository) of the Cai et al. (2019) and processes it so that it is a properly formatted CSV file that can be read by pandas and follows exactly the Cai et al. (2019) and Pan et al. (2020) papers. Args: url: the url location of the dataset to download as a string. output_file: the output path of the CSV file to write to as a string. text_index: the index of the text column (the tweet text) as an int. labels_index: the index of the label column (the sarcasm label) as an int. to_filter: a boolean to indicate if this dataset should be filtered as per the papers preprocessing rules. \"\"\" with open(output_file, 'w', newline='', encoding='utf-8') as csv_file: csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) csv_writer.writerow(['text', 'labels']) file = urllib.request.urlopen(url) for line in file: decoded_line = line.decode('utf-8') row = eval(decoded_line) if not to_filter or not filtered(row[text_index]): csv_writer.writerow([row[text_index], row[labels_index]]) Now we use the above functions to download and pre-process the train, test and validation datasets from the paper‚Äôs Github data repository. The output file are written to the local storage of the notebook as train.csv, test.csv and validate.csv.\ndownload_and_clean('https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/train.txt', 'train.csv', 1, 2, to_filter=True) download_and_clean('https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/test2.txt', 'test.csv', 1, 3) download_and_clean('https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/valid2.txt', 'validate.csv', 1, 3) Now we use pandas to read in the well-formatted train.csv, test.csv and validate.csv files into dataframes. We also take a look at the first few rows of the training set with the .head() function to check if our CSV files are loaded properly.\nimport pandas as pd train_df = pd.read_csv('train.csv') test_df = pd.read_csv('test.csv') validate_df = pd.read_csv('validate.csv') train_df.head() Next, we compare if our dataset size, after the pre-processing, is exactly the same as those reported in both the papers. 0 is the not sarcastic class while 1 is the sarcastic class.\nThe paper reports the following dataset class sizes for train, test and validate (used as the dev) sets.\n   Label Train Test Validate     0 11174 1450 1451   1 8642 959 959    data = [[train_df.labels.value_counts()[0], test_df.labels.value_counts()[0], validate_df.labels.value_counts()[0]], [train_df.labels.value_counts()[1], test_df.labels.value_counts()[1], validate_df.labels.value_counts()[1]]] # Prints out the dataset sizes of train test and validate as per the table. pd.DataFrame(data, columns=[\"Train\", \"Test\", \"Validate\"]) We are now confident that we have the exact dataset as reported in both the papers, we can go on to train our model to do sarcasm detection.\nTraining and Testing the Model Set the Hyperparmeters First we setup the hyperparamters, using the hyperparemeters specified in the Pan et al. (2020) paper whenever possible. The comparison of hyperparameters are shown in the table below. The major difference is we only train 1 epoch instead of 8 as we want the training to be fast.\n   Parameter Ours Paper     Epochs 1 8   Batch Size 32 32   Seq Length 75 75   Learning Rate 5e-5 5e-5   Weight decay 1e-2 1e-2   Warmup rate 0.2 0.2   Gradient Clipping 1.0 1.0    train_args = { 'reprocess_input_data': True, 'overwrite_output_dir': True, 'sliding_window': False, 'max_seq_length': 75, 'learning_rate': 0.00005, 'weight_decay': 0.01, 'warmup_ratio': 0.2, 'max_grad_norm': 1.0, 'num_train_epochs': 1, 'train_batch_size': 32, 'save_model_every_epoch': False, 'save_steps': 4000, 'fp16': True, 'output_dir': '/outputs/', 'evaluate_during_training': True, } Train the Model Once we have setup the hyperparemeters in the train_args dictionary, the next step would be to train the model. We use the roberta-base model from the awesome Hugging Face Transformers library and use the Simple Transformers library on top of it to make it so we can train the classification model with just 2 lines of code.\nRoBERTa is an optimized BERT model by Facebook Research with better performance on the masked language modeling objective that modifies key hyperparameters in BERT, including removing BERT‚Äôs next-sentence pretraining objective, and training with much larger mini-batches and learning rates. In short, its a bigger but generally better performing BERT model we can easily plug in here with the transformers library.\nfrom simpletransformers.classification import ClassificationModel import pandas as pd import logging import sklearn logging.basicConfig(level=logging.DEBUG) transformers_logger = logging.getLogger('transformers') transformers_logger.setLevel(logging.WARNING) # We use the RoBERTa base pre-trained model. model = ClassificationModel('roberta', 'roberta-base', num_labels=2, args=train_args) # Train the model, use the validation set as the development set as per the paper. # When training to 1 epoch this is not that essential, however, if you decide to  # train more and configure early stopping, do check out the simple transformers # documentation: https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping model.train_model(train_df, eval_df=validate_df) # Evaluate the model in terms of accuracy score result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.accuracy_score) We see that the output accuracy from the model after training for 1 epoch is 93.7% (‚Äòacc‚Äô: 0.9369032793690328).\nEvaluate the Model (F1-score) Now we want to calculate the F1-score for the model.\nSince the class distribution (the number of sacarstic vs not sarcastic) is not balanced, F1-score is a better accuracy measure. We calculate the F1-score of the model on the test set below.\nresult, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.f1_score) The F1-score is 92.2% (‚Äòacc‚Äô: 0.9224489795918368) is 9.4 points better than the state-of-the-art results reported in the Pan et al. (2020) paper at 82.9% using just the textual features with RoBERTa instead of BERT.\n We‚Äôve just trained a new state-of-the-art sarcasm detection model from tweet text!\n Using the Model (Running Inference) Running the model to do some predictions/inference is as simple as calling model.predict(input_list).\nsamples = ['hell yeah ! # funny # sleepwell # dreamon # fail', 'i could enter the olympics ! ;) rt  : ', 'we ‚Äô re excited to hold a q \u0026 a session with  tomorrow courtesy of  ! submit your questions by using # askabluejay ! # wt2017'] predictions, _ = model.predict(samples) label_dict = {0: 'not sarcastic', 1: 'sarcastic'} for idx, sample in enumerate(samples): print('{}: {}, {}'.format(idx, sample, label_dict[predictions[idx]])) We can connect to Google Drive with the following code to save any files you want to persist. You can also click the Files icon on the left panel and click Mount Drive to mount your Google Drive.\nThe root of your Google Drive will be mounted to /content/drive/My Drive/. If you have problems mounting the drive, you can check out this tutorial.\nfrom google.colab import drive drive.mount('/content/drive/') You can move the train.csv file from our local directory to your Google Drive. You can do the same for the model checkpount files which are saved in the /content/outputs/best_model/ directory.\nimport shutil shutil.move('/content/train.csv', \"/content/drive/My Drive/train.csv\") Discussion With an accuracy of 92%, have we solved sarcasm detection? Probably not. We know we have trained a classification model that is great on this dataset with only text content as input, however, if we go back to the task definition, we think that a correct understanding of sarcasm often requires a deep understanding of multiple sources of information, including the utterance, the conversational context, and, frequently some real world facts.\nIt‚Äôs certainly possible (and quite trivial) to pick out counterexamples of tweets with little context that could be classified as sarcastic. It is also possible to study these results and this dataset in greater detail (confusion matrix, eyeballing), but it will probably lead to limited insights. Check out more notebooks and check back as we update the repo with more practical ML in NLP and sarcasm detection as things develop on the SOTA frontier.\nMore Such Notebooks Visit or star the eugenesiow/practical-ml repository on Github for more such notebooks:\n Alternatives to Colab Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:\n Google Colab vs Paperspace Gradient  ","wordCount":"1938","inLanguage":"en","image":"https://news.machinelearning.sg/sarcasm_detection.png","datePublished":"2020-12-22T09:00:00+08:00","dateModified":"2020-12-22T09:00:00+08:00","author":{"@type":"Person","name":"Eugene"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/"},"publisher":{"@type":"Organization","name":"News @ machinelearning.sg","logo":{"@type":"ImageObject","url":"https://news.machinelearning.sg/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://news.machinelearning.sg/ accesskey=h>News</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span><span class=lang-switch><ul><li><a href=https://machinelearning.sg>machinelearning.sg</a></li></ul></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://news.machinelearning.sg/about/><span>About</span></a></li><li><a href=https://news.machinelearning.sg/archives/><span>Archive</span></a></li><li><a href=https://news.machinelearning.sg/tags/><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Learn to Train a State-of-the-Art Model for Sarcasm Detection</h1><div class=post-meta>December 22, 2020&nbsp;¬∑&nbsp;10 min&nbsp;¬∑&nbsp;Eugene</div></header><figure class=entry-cover><img srcset="https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection_hucd0535b5ba689da8e7861243f4ad9cd2_299978_360x0_resize_box_2.png 360w ,https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection_hucd0535b5ba689da8e7861243f4ad9cd2_299978_480x0_resize_box_2.png 480w ,https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection_hucd0535b5ba689da8e7861243f4ad9cd2_299978_720x0_resize_box_2.png 720w ,https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection_hucd0535b5ba689da8e7861243f4ad9cd2_299978_1080x0_resize_box_2.png 1080w ,https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection.png 1477w" sizes="(min-width: 768px) 720px, 100vw" src=https://news.machinelearning.sg/posts/learn_to_train_a_state_of_the_art_model_for_sarcasm_detection/sarcasm_detection.png alt="Sarcasm Detection on Tweets"></figure><div class=toc><details><summary><div class=details accesskey=c>Table of Contents</div></summary><blockquote><ul><li><a href=#sooo-impressive-sarcasm-detection-model-on-tweets aria-label="Sooo Impressive Sarcasm Detection Model on Tweets">Sooo Impressive Sarcasm Detection Model on Tweets</a><ul><ul><li><a href=# aria-label="Heatmap Visualization of Attention Focus on Images of Sarcastic Tweets. Retrieved from the official paper.">Heatmap Visualization of Attention Focus on Images of Sarcastic Tweets. Retrieved from the official paper.</a></li></ul></ul></li><li><a href=#practical-machine-learning---learn-step-by-step-to-train-a-model aria-label="Practical Machine Learning - Learn Step-by-Step to Train a Model">Practical Machine Learning - Learn Step-by-Step to Train a Model</a></li><li><a href=#sarcasm-detection-on-twitter-data aria-label="Sarcasm Detection on Twitter Data">Sarcasm Detection on Twitter Data</a><ul><ul><li><a href=#task-description aria-label="Task Description">Task Description</a></li></ul></ul></li><li><a href=#setting-up-the-gpu-environment aria-label="Setting up the GPU Environment">Setting up the GPU Environment</a><ul><ul><li><a href=#ensure-we-have-a-gpu-runtime aria-label="Ensure we have a GPU runtime">Ensure we have a GPU runtime</a></li><li><a href=#install-dependencies-and-restart-runtime aria-label="Install Dependencies and Restart Runtime">Install Dependencies and Restart Runtime</a></li></ul></ul></li><li><a href=#getting-data aria-label="Getting Data">Getting Data</a></li><li><a href=#training-and-testing-the-model aria-label="Training and Testing the Model">Training and Testing the Model</a><ul><ul><li><a href=#set-the-hyperparmeters aria-label="Set the Hyperparmeters">Set the Hyperparmeters</a></li><li><a href=#train-the-model aria-label="Train the Model">Train the Model</a></li><li><a href=#evaluate-the-model-f1-score aria-label="Evaluate the Model (F1-score)">Evaluate the Model (F1-score)</a></li></ul></ul></li><li><a href=#using-the-model-running-inference aria-label="Using the Model (Running Inference)">Using the Model (Running Inference)</a><ul><ul><li><a href=#discussion aria-label=Discussion>Discussion</a></li></ul></ul></li><li><a href=#more-such-notebooks aria-label="More Such Notebooks">More Such Notebooks</a></li><li><a href=#alternatives-to-colab aria-label="Alternatives to Colab">Alternatives to Colab</a></li></ul></blockquote></details></div><div class=post-content><blockquote><p><strong>tl;dr</strong> A step-by-step tutorial to train a state-of-the-art model to detect sarcasm üôÑ from tweets with a
free Jupyter Notebook in the cloud.</p></blockquote><h2 id=sooo-impressive-sarcasm-detection-model-on-tweets>Sooo Impressive Sarcasm Detection Model on Tweets<a hidden class=anchor aria-hidden=true href=#sooo-impressive-sarcasm-detection-model-on-tweets>#</a></h2><p>Recently Venture Beat published (and <a href=https://cacm.acm.org/careers/248837-ai-researchers-made-a-sarcasm-detection-model-and-its-sooo-impressive/fulltext>Communications of the ACM</a> referenced)<br>a news article titled &ldquo;<a href=https://venturebeat.com/2020/11/18/ai-researchers-made-a-sarcasm-detection-model-and-its-soo-impressive/>AI researchers made a sarcasm detection model and it‚Äôs sooo impressive</a>&rdquo;
which detailed how researchers from China had come up with a &ldquo;sarcasm detection AI&rdquo; that &ldquo;achieved state-of-the-art
performance on a dataset drawn from Twitter&rdquo;.</p><p>What is interesting about the AI model was that it used multimodal learning to combine text and imagery from the tweets
to do this sarcasm detection, &ldquo;since both are often needed to understand whether a person is being sarcastic&rdquo;.</p><figure><img src=sarcasm_detection_photos.jpg><figcaption><h4>Heatmap Visualization of Attention Focus on Images of Sarcastic Tweets. Retrieved from the official paper.</h4></figcaption></figure><p>The premise and findings like the above figure were interesting and kudos to the team behind the paper.</p><p>In this step-by-step practical, we will learn to train a model that has better performance (F1-score) than this
state-of-the-art model on the same dataset while using only the text from the tweets.</p><h2 id=practical-machine-learning---learn-step-by-step-to-train-a-model>Practical Machine Learning - Learn Step-by-Step to Train a Model<a hidden class=anchor aria-hidden=true href=#practical-machine-learning---learn-step-by-step-to-train-a-model>#</a></h2><p>A great way to learn is by going step-by-step through the process of training and evaluating the model.</p><p>In this step-by-step practical, we will learn to train a model that has better performance (F1-score) than the
state-of-the-art model.</p><p>Hit the <strong><code>Open in Colab</code></strong> button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough.
<a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sarcasm_Detection_Twitter.ipynb title="Open in Colab"><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Continue on if you prefer reading the code here.</p><h2 id=sarcasm-detection-on-twitter-data>Sarcasm Detection on Twitter Data<a hidden class=anchor aria-hidden=true href=#sarcasm-detection-on-twitter-data>#</a></h2><p><a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sarcasm_Detection_Twitter.ipynb title="Open in Colab"><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Notebook to train a BERT-based (RoBERTa) model to perform sarcasm detection. The dataset used is a collection of (more than 20,000) tweets with binary labels: <strong><code>not sarcastic</code></strong> or <strong><code>sarcastic</code></strong> from the paper by <a href=https://www.aclweb.org/anthology/P19-1239/>Cai et al. (2019)</a>. The trained model beats the state-of-the-art at this time (Dec 2020). The current state-of-the-art model on this dataset by <a href=https://www.aclweb.org/anthology/2020.findings-emnlp.124/>Pan et al. (2020)</a> uses additional information of features from hash-tags and and the image posted along with the tweet (multi-modal sarcasm detection) whereas this model uses just the textual features.</p><p>The notebook is structured as follows:</p><ul><li>Setting up the GPU Environment</li><li>Getting Data</li><li>Training and Testing the Model</li><li>Using the Model (Running Inference)</li></ul><h4 id=task-description>Task Description<a hidden class=anchor aria-hidden=true href=#task-description>#</a></h4><blockquote><p>The goal of Sarcasm Detection is to determine whether a sentence is sarcastic or non-sarcastic. Sarcasm is a type of phenomenon with specific perlocutionary effects on the hearer, such as to break their pattern of expectation. Consequently, correct understanding of sarcasm often requires a deep understanding of multiple sources of information, including the utterance, the conversational context, and, frequently some real world facts.</p></blockquote><p>Source: <a href=https://arxiv.org/abs/1809.03051>Attentional Multi-Reading Sarcasm Detection</a></p><h2 id=setting-up-the-gpu-environment>Setting up the GPU Environment<a hidden class=anchor aria-hidden=true href=#setting-up-the-gpu-environment>#</a></h2><h4 id=ensure-we-have-a-gpu-runtime>Ensure we have a GPU runtime<a hidden class=anchor aria-hidden=true href=#ensure-we-have-a-gpu-runtime>#</a></h4><p>If you&rsquo;re running this notebook in Google Colab, select <code>Runtime</code> > <code>Change Runtime Type</code> from the menubar. Ensure that <code>GPU</code> is selected as the <code>Hardware accelerator</code>. This will allow us to use the GPU to train the model subsequently.</p><h4 id=install-dependencies-and-restart-runtime>Install Dependencies and Restart Runtime<a hidden class=anchor aria-hidden=true href=#install-dependencies-and-restart-runtime>#</a></h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>!pip install -q transformers
!pip install -q simpletransformers
</code></pre></div><p>You might see the error <code>ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible</code> after installing the dependencies. <strong>This is normal</strong> and caused by the <code>simpletransformers</code> library.</p><p>The <strong>solution</strong> to this will be to <strong>reset the execution environment</strong> now. Go to the menu <code>Runtime</code> > <code>Restart runtime</code> then continue on from the next section to download and process the data.</p><h2 id=getting-data>Getting Data<a hidden class=anchor aria-hidden=true href=#getting-data>#</a></h2><p>Here are the functions that will allow us to download the dataset from the <a href=https://github.com/headacheboy/data-of-multimodal-sarcasm-detection>Github data repository</a> of the paper by <a href=https://www.aclweb.org/anthology/P19-1239/>Cai et al. (2019)</a>. The function will also process the dataset so we can read it into <a href=https://pandas.pydata.org/pandas-docs/stable/index.html#>pandas</a>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> csv
<span style=color:#f92672>import</span> urllib.request


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>filtered</span>(sentence):
  <span style=color:#e6db74>&#34;&#34;&#34;Filter function that indication if sentence should be filtered.
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>  Filtering function that is adapted from the original, more verbose, 
</span><span style=color:#e6db74>  pre-processing script from the Cai et al. (2019) paper:
</span><span style=color:#e6db74>  https://github.com/headacheboy/data-of-multimodal-sarcasm-detection/blob/master/codes/loadData.py
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>  Args:
</span><span style=color:#e6db74>      sentence: A string of the sentence to be filtered.
</span><span style=color:#e6db74>      
</span><span style=color:#e6db74>  Returns:
</span><span style=color:#e6db74>      A boolean value (True or False) that indicates if a sentence should be 
</span><span style=color:#e6db74>      filtered of based on the criterea by Cai et al. (2019).
</span><span style=color:#e6db74>  &#34;&#34;&#34;</span>
  words <span style=color:#f92672>=</span> sentence<span style=color:#f92672>.</span>split()
  filter <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;sarcasm&#39;</span>, <span style=color:#e6db74>&#39;sarcastic&#39;</span>, <span style=color:#e6db74>&#39;reposting&#39;</span>, <span style=color:#e6db74>&#39;&lt;url&gt;&#39;</span>, <span style=color:#e6db74>&#39;joke&#39;</span>, <span style=color:#e6db74>&#39;humour&#39;</span>, <span style=color:#e6db74>&#39;humor&#39;</span>, <span style=color:#e6db74>&#39;jokes&#39;</span>, <span style=color:#e6db74>&#39;irony&#39;</span>, <span style=color:#e6db74>&#39;ironic&#39;</span>, <span style=color:#e6db74>&#39;exgag&#39;</span>]
  <span style=color:#66d9ef>for</span> filtered_word <span style=color:#f92672>in</span> filter:
    <span style=color:#66d9ef>if</span> filtered_word <span style=color:#f92672>in</span> words:
      <span style=color:#66d9ef>return</span> True
  <span style=color:#66d9ef>return</span> False


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>download_and_clean</span>(url, output_file, text_index, labels_index, to_filter<span style=color:#f92672>=</span>False):
  <span style=color:#e6db74>&#34;&#34;&#34;Download and pre-process the paper&#39;s tweet dataset.
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>  Downloads the dataset from a url (github repository) of the Cai et al. (2019)
</span><span style=color:#e6db74>  and processes it so that it is a properly formatted CSV file that can be read
</span><span style=color:#e6db74>  by pandas and follows exactly the Cai et al. (2019) and Pan et al. (2020) 
</span><span style=color:#e6db74>  papers.
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>  Args:
</span><span style=color:#e6db74>      url: the url location of the dataset to download as a string.
</span><span style=color:#e6db74>      output_file: the output path of the CSV file to write to as a string.
</span><span style=color:#e6db74>      text_index: the index of the text column (the tweet text) as an int.
</span><span style=color:#e6db74>      labels_index: the index of the label column (the sarcasm label) as an int.
</span><span style=color:#e6db74>      to_filter: a boolean to indicate if this dataset should be filtered as
</span><span style=color:#e6db74>        per the papers preprocessing rules.
</span><span style=color:#e6db74>  &#34;&#34;&#34;</span>
  <span style=color:#66d9ef>with</span> open(output_file, <span style=color:#e6db74>&#39;w&#39;</span>, newline<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;utf-8&#39;</span>) <span style=color:#66d9ef>as</span> csv_file:
    csv_writer <span style=color:#f92672>=</span> csv<span style=color:#f92672>.</span>writer(csv_file, delimiter<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;,&#39;</span>, quotechar<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#34;&#39;</span>, quoting<span style=color:#f92672>=</span>csv<span style=color:#f92672>.</span>QUOTE_MINIMAL)
    csv_writer<span style=color:#f92672>.</span>writerow([<span style=color:#e6db74>&#39;text&#39;</span>, <span style=color:#e6db74>&#39;labels&#39;</span>])
    file <span style=color:#f92672>=</span> urllib<span style=color:#f92672>.</span>request<span style=color:#f92672>.</span>urlopen(url)
    <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> file:
      decoded_line <span style=color:#f92672>=</span> line<span style=color:#f92672>.</span>decode(<span style=color:#e6db74>&#39;utf-8&#39;</span>)
      row <span style=color:#f92672>=</span> eval(decoded_line)
      <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> to_filter <span style=color:#f92672>or</span> <span style=color:#f92672>not</span> filtered(row[text_index]):
        csv_writer<span style=color:#f92672>.</span>writerow([row[text_index], row[labels_index]])
</code></pre></div><p>Now we use the above functions to download and pre-process the train, test and validation datasets from the paper&rsquo;s Github data repository. The output file are written to the local storage of the notebook as <code>train.csv</code>, <code>test.csv</code> and <code>validate.csv</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>download_and_clean(<span style=color:#e6db74>&#39;https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/train.txt&#39;</span>, <span style=color:#e6db74>&#39;train.csv&#39;</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, to_filter<span style=color:#f92672>=</span>True)
download_and_clean(<span style=color:#e6db74>&#39;https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/test2.txt&#39;</span>, <span style=color:#e6db74>&#39;test.csv&#39;</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>)
download_and_clean(<span style=color:#e6db74>&#39;https://raw.githubusercontent.com/headacheboy/data-of-multimodal-sarcasm-detection/master/text/valid2.txt&#39;</span>, <span style=color:#e6db74>&#39;validate.csv&#39;</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>)
</code></pre></div><p>Now we use pandas to read in the well-formatted <code>train.csv</code>, <code>test.csv</code> and <code>validate.csv</code> files into dataframes. We also take a look at the first few rows of the training set with the <code>.head()</code> function to check if our CSV files are loaded properly.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> pandas <span style=color:#f92672>as</span> pd
train_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;train.csv&#39;</span>)
test_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;test.csv&#39;</span>)
validate_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;validate.csv&#39;</span>)
train_df<span style=color:#f92672>.</span>head()
</code></pre></div><p>Next, we compare if our dataset size, after the pre-processing, is exactly the same as those reported in both the papers. <strong><code>0</code></strong> is the <strong><code>not sarcastic</code></strong> class while <strong><code>1</code></strong> is the <strong><code>sarcastic</code></strong> class.</p><p>The paper reports the following dataset class sizes for train, test and validate (used as the dev) sets.</p><table><thead><tr><th>Label</th><th>Train</th><th>Test</th><th>Validate</th></tr></thead><tbody><tr><td>0</td><td>11174</td><td>1450</td><td>1451</td></tr><tr><td>1</td><td>8642</td><td>959</td><td>959</td></tr></tbody></table><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data <span style=color:#f92672>=</span> [[train_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>0</span>], test_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>0</span>], validate_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>0</span>]], 
        [train_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>1</span>], test_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>1</span>], validate_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>1</span>]]]
<span style=color:#75715e># Prints out the dataset sizes of train test and validate as per the table.</span>
pd<span style=color:#f92672>.</span>DataFrame(data, columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;Train&#34;</span>, <span style=color:#e6db74>&#34;Test&#34;</span>, <span style=color:#e6db74>&#34;Validate&#34;</span>])
</code></pre></div><p>We are now confident that we have the exact dataset as reported in both the papers, we can go on to train our model to do sarcasm detection.</p><h2 id=training-and-testing-the-model>Training and Testing the Model<a hidden class=anchor aria-hidden=true href=#training-and-testing-the-model>#</a></h2><h4 id=set-the-hyperparmeters>Set the Hyperparmeters<a hidden class=anchor aria-hidden=true href=#set-the-hyperparmeters>#</a></h4><p>First we setup the hyperparamters, using the hyperparemeters specified in the Pan et al. (2020) paper whenever possible. The comparison of hyperparameters are shown in the table below. The major difference is we only train 1 epoch instead of 8 as we want the training to be fast.</p><table><thead><tr><th>Parameter</th><th>Ours</th><th>Paper</th></tr></thead><tbody><tr><td>Epochs</td><td>1</td><td>8</td></tr><tr><td>Batch Size</td><td>32</td><td>32</td></tr><tr><td>Seq Length</td><td>75</td><td>75</td></tr><tr><td>Learning Rate</td><td>5e-5</td><td>5e-5</td></tr><tr><td>Weight decay</td><td>1e-2</td><td>1e-2</td></tr><tr><td>Warmup rate</td><td>0.2</td><td>0.2</td></tr><tr><td>Gradient Clipping</td><td>1.0</td><td>1.0</td></tr></tbody></table><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_args <span style=color:#f92672>=</span> {
    <span style=color:#e6db74>&#39;reprocess_input_data&#39;</span>: True,
    <span style=color:#e6db74>&#39;overwrite_output_dir&#39;</span>: True,
    <span style=color:#e6db74>&#39;sliding_window&#39;</span>: False,
    <span style=color:#e6db74>&#39;max_seq_length&#39;</span>: <span style=color:#ae81ff>75</span>,
    <span style=color:#e6db74>&#39;learning_rate&#39;</span>: <span style=color:#ae81ff>0.00005</span>,
    <span style=color:#e6db74>&#39;weight_decay&#39;</span>: <span style=color:#ae81ff>0.01</span>,
    <span style=color:#e6db74>&#39;warmup_ratio&#39;</span>: <span style=color:#ae81ff>0.2</span>,
    <span style=color:#e6db74>&#39;max_grad_norm&#39;</span>: <span style=color:#ae81ff>1.0</span>,
    <span style=color:#e6db74>&#39;num_train_epochs&#39;</span>: <span style=color:#ae81ff>1</span>,
    <span style=color:#e6db74>&#39;train_batch_size&#39;</span>: <span style=color:#ae81ff>32</span>,
    <span style=color:#e6db74>&#39;save_model_every_epoch&#39;</span>: False,
    <span style=color:#e6db74>&#39;save_steps&#39;</span>: <span style=color:#ae81ff>4000</span>,
    <span style=color:#e6db74>&#39;fp16&#39;</span>: True,
    <span style=color:#e6db74>&#39;output_dir&#39;</span>: <span style=color:#e6db74>&#39;/outputs/&#39;</span>,
    <span style=color:#e6db74>&#39;evaluate_during_training&#39;</span>: True,
}
</code></pre></div><h4 id=train-the-model>Train the Model<a hidden class=anchor aria-hidden=true href=#train-the-model>#</a></h4><p>Once we have setup the hyperparemeters in the <code>train_args</code> dictionary, the next step would be to train the model. We use the <a href=https://huggingface.co/roberta-base><code>roberta-base</code> model</a> from the awesome <a href=https://github.com/huggingface/transformers>Hugging Face Transformers</a> library and use the <a href=https://simpletransformers.ai/docs/classification-models/>Simple Transformers library</a> on top of it to make it so we can train the classification model with just 2 lines of code.</p><p><a href=https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/>RoBERTa</a> is an optimized BERT model by Facebook Research with better performance on the masked language modeling objective that modifies key hyperparameters in BERT, including removing BERT&rsquo;s next-sentence pretraining objective, and training with much larger mini-batches and learning rates. In short, its a bigger but generally better performing BERT model we can easily plug in here with the transformers library.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> simpletransformers.classification <span style=color:#f92672>import</span> ClassificationModel
<span style=color:#f92672>import</span> pandas <span style=color:#f92672>as</span> pd
<span style=color:#f92672>import</span> logging
<span style=color:#f92672>import</span> sklearn

logging<span style=color:#f92672>.</span>basicConfig(level<span style=color:#f92672>=</span>logging<span style=color:#f92672>.</span>DEBUG)
transformers_logger <span style=color:#f92672>=</span> logging<span style=color:#f92672>.</span>getLogger(<span style=color:#e6db74>&#39;transformers&#39;</span>)
transformers_logger<span style=color:#f92672>.</span>setLevel(logging<span style=color:#f92672>.</span>WARNING)

<span style=color:#75715e># We use the RoBERTa base pre-trained model.</span>
model <span style=color:#f92672>=</span> ClassificationModel(<span style=color:#e6db74>&#39;roberta&#39;</span>, <span style=color:#e6db74>&#39;roberta-base&#39;</span>, num_labels<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, args<span style=color:#f92672>=</span>train_args) 

<span style=color:#75715e># Train the model, use the validation set as the development set as per the paper.</span>
<span style=color:#75715e># When training to 1 epoch this is not that essential, however, if you decide to </span>
<span style=color:#75715e># train more and configure early stopping, do check out the simple transformers</span>
<span style=color:#75715e># documentation: https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping</span>
model<span style=color:#f92672>.</span>train_model(train_df, eval_df<span style=color:#f92672>=</span>validate_df)

<span style=color:#75715e># Evaluate the model in terms of accuracy score</span>
result, model_outputs, wrong_predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>eval_model(test_df, acc<span style=color:#f92672>=</span>sklearn<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>accuracy_score)
</code></pre></div><p>We see that the output accuracy from the model after training for 1 epoch is <strong>93.7%</strong> (&lsquo;acc&rsquo;: 0.9369032793690328).</p><h4 id=evaluate-the-model-f1-score>Evaluate the Model (F1-score)<a hidden class=anchor aria-hidden=true href=#evaluate-the-model-f1-score>#</a></h4><p>Now we want to calculate the F1-score for the model.</p><p>Since the class distribution (the number of <strong><code>sacarstic</code></strong> vs <strong><code>not sarcastic</code></strong>) is not balanced, <a href=https://sebastianraschka.com/faq/docs/computing-the-f1-score.html>F1-score is a better accuracy measure</a>. We calculate the F1-score of the model on the test set below.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>result, model_outputs, wrong_predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>eval_model(test_df, acc<span style=color:#f92672>=</span>sklearn<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>f1_score)
</code></pre></div><p>The F1-score is <strong>92.2%</strong> (&lsquo;acc&rsquo;: 0.9224489795918368) is <strong>9.4 points</strong> better than the state-of-the-art results reported in the Pan et al. (2020) paper at <strong>82.9%</strong> using just the textual features with RoBERTa instead of BERT.</p><blockquote><p>We&rsquo;ve just trained a new state-of-the-art sarcasm detection model from tweet text!</p></blockquote><h2 id=using-the-model-running-inference>Using the Model (Running Inference)<a hidden class=anchor aria-hidden=true href=#using-the-model-running-inference>#</a></h2><p>Running the model to do some predictions/inference is as simple as calling <code>model.predict(input_list)</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>samples <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;hell yeah !  # funny # sleepwell # dreamon # fail&#39;</span>,
           <span style=color:#e6db74>&#39;i could enter the olympics ! ;) rt &lt;user&gt; : &#39;</span>,
           <span style=color:#e6db74>&#39;we ‚Äô re excited to hold a q &amp; a session with &lt;user&gt; tomorrow courtesy of &lt;user&gt; ! submit your questions by using # askabluejay ! # wt2017&#39;</span>]
predictions, _ <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(samples)
label_dict <span style=color:#f92672>=</span> {<span style=color:#ae81ff>0</span>: <span style=color:#e6db74>&#39;not sarcastic&#39;</span>, <span style=color:#ae81ff>1</span>: <span style=color:#e6db74>&#39;sarcastic&#39;</span>}
<span style=color:#66d9ef>for</span> idx, sample <span style=color:#f92672>in</span> enumerate(samples):
  <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;{}: {}, {}&#39;</span><span style=color:#f92672>.</span>format(idx, sample, label_dict[predictions[idx]]))
</code></pre></div><p>We can connect to Google Drive with the following code to save any files you want to persist. You can also click the <code>Files</code> icon on the left panel and click <code>Mount Drive</code> to mount your Google Drive.</p><p>The root of your Google Drive will be mounted to <code>/content/drive/My Drive/</code>. If you have problems mounting the drive, you can check out this <a href=https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166>tutorial</a>.</p><pre><code>from google.colab import drive
drive.mount('/content/drive/')
</code></pre><p>You can move the <code>train.csv</code> file from our local directory to your Google Drive. You can do the same for the model checkpount files which are saved in the <code>/content/outputs/best_model/</code> directory.</p><pre><code>import shutil
shutil.move('/content/train.csv', &quot;/content/drive/My Drive/train.csv&quot;)
</code></pre><h4 id=discussion>Discussion<a hidden class=anchor aria-hidden=true href=#discussion>#</a></h4><p>With an accuracy of >92%, have we solved sarcasm detection? Probably not. We know we have trained a classification model that is great on this dataset with only text content as input, however, if we go back to the task definition, we think that a correct understanding of sarcasm <em>often requires a deep understanding of multiple sources of information, including the utterance, the conversational context, and, frequently some real world facts</em>.</p><p>It&rsquo;s certainly possible (and quite trivial) to pick out counterexamples of tweets with little context that could be classified as sarcastic. It is also possible to study these results and this dataset in greater detail (confusion matrix, eyeballing), but it will probably lead to limited insights. Check out more notebooks and check back as we update the repo with more practical ML in NLP and sarcasm detection as things develop on the SOTA frontier.</p><h2 id=more-such-notebooks>More Such Notebooks<a hidden class=anchor aria-hidden=true href=#more-such-notebooks>#</a></h2><p>Visit or star the <a href=https://github.com/eugenesiow/practical-ml>eugenesiow/practical-ml</a> repository on Github for more such notebooks:</p><iframe src="https://ghbtns.com/github-btn.html?user=eugenesiow&repo=practical-ml&type=star&count=true&size=large" frameborder=0 scrolling=0 width=170 height=30 title="Practical Machine Learning"></iframe><h2 id=alternatives-to-colab>Alternatives to Colab<a hidden class=anchor aria-hidden=true href=#alternatives-to-colab>#</a></h2><p>Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:</p><ul><li><a href=https://news.machinelearning.sg/posts/google_colab_vs_paperspace_gradient/>Google Colab vs Paperspace Gradient</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://news.machinelearning.sg/tags/natural-language-processing>Natural Language Processing</a></li><li><a href=https://news.machinelearning.sg/tags/deep-learning>Deep Learning</a></li><li><a href=https://news.machinelearning.sg/tags/machine-learning>Machine Learning</a></li><li><a href=https://news.machinelearning.sg/tags/gpu>GPU</a></li><li><a href=https://news.machinelearning.sg/tags/source-code>Source Code</a></li><li><a href=https://news.machinelearning.sg/tags/pytorch>PyTorch</a></li><li><a href=https://news.machinelearning.sg/tags/sarcasm-detection>Sarcasm Detection</a></li><li><a href=https://news.machinelearning.sg/tags/jupyter-notebook>Jupyter Notebook</a></li><li><a href=https://news.machinelearning.sg/tags/colab>Colab</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on twitter" href="https://twitter.com/intent/tweet/?text=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f&hashtags=NaturalLanguageProcessing%2cDeepLearning%2cMachineLearning%2cGPU%2cSourceCode%2cPyTorch%2cSarcasmDetection%2cJupyterNotebook%2cColab"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f&title=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection&summary=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection&source=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f&title=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on whatsapp" href="https://api.whatsapp.com/send?text=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection%20-%20https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learn to Train a State-of-the-Art Model for Sarcasm Detection on telegram" href="https://telegram.me/share/url?text=Learn%20to%20Train%20a%20State-of-the-Art%20Model%20for%20Sarcasm%20Detection&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2flearn_to_train_a_state_of_the_art_model_for_sarcasm_detection%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2020 <a href=https://news.machinelearning.sg/>News @ machinelearning.sg</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=https://news.machinelearning.sg/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>