<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Sentiment Analysis in Mandarin with XLNet | News @ machinelearning.sg</title><meta name=keywords content="Natural Language Processing,Deep Learning,Machine Learning,GPU,Source Code,PyTorch,Sentiment Analysis,Jupyter Notebook,Colab"><meta name=description content="tl;dr A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery reviews using the XLNet architecture. We will use Google Colab&rsquo;s free Jupyter Notebook in the cloud.
 Practical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.
Hit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough."><meta name=author content="Eugene"><link rel=canonical href=https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/><link href=https://news.machinelearning.sg/assets/css/stylesheet.min.62447981861ad5bc7761e73be43801fe136a2aaaa8b7afd18ce582c358716848.css integrity="sha256-YkR5gYYa1bx3Yec75DgB/hNqKqqot6/RjOWCw1hxaEg=" rel="preload stylesheet" as=style><link rel=icon href=https://news.machinelearning.sg/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://news.machinelearning.sg/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://news.machinelearning.sg/favicon-32x32.png><link rel=apple-touch-icon href=https://news.machinelearning.sg/apple-touch-icon.png><link rel=mask-icon href=https://news.machinelearning.sg/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.79.0"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-185405110-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Sentiment Analysis in Mandarin with XLNet"><meta property="og:description" content="tl;dr A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery reviews using the XLNet architecture. We will use Google Colab&rsquo;s free Jupyter Notebook in the cloud.
 Practical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.
Hit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough."><meta property="og:type" content="article"><meta property="og:url" content="https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/"><meta property="og:image" content="https://news.machinelearning.sg/sa_mandarin.png"><meta property="article:published_time" content="2020-12-23T10:00:00+08:00"><meta property="article:modified_time" content="2020-12-23T10:00:00+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://news.machinelearning.sg/sa_mandarin.png"><meta name=twitter:title content="Sentiment Analysis in Mandarin with XLNet"><meta name=twitter:description content="tl;dr A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery reviews using the XLNet architecture. We will use Google Colab&rsquo;s free Jupyter Notebook in the cloud.
 Practical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.
Hit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Sentiment Analysis in Mandarin with XLNet","name":"Sentiment Analysis in Mandarin with XLNet","description":"tl;dr A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery reviews using the XLNet architecture. We will use Google …","keywords":["Natural Language Processing","Deep Learning","Machine Learning","GPU","Source Code","PyTorch","Sentiment Analysis","Jupyter Notebook","Colab"],"articleBody":" tl;dr A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery reviews using the XLNet architecture. We will use Google Colab’s free Jupyter Notebook in the cloud.\n Practical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.\nHit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough. \nContinue on if you prefer reading the code here.\nSentiment Analysis in Mandarin on Food Delivery Reviews, 情感分析 \nNotebook to train a mandarin XLNet model to perform sentiment analysis. The dataset used is the unbalanced WAIMAI_10K (10,000 food delivery reviews from a food delivery platform in China). The dataset has binary labels: postive or negative. There is no published state-of-the-art model that we know of on this dataset, however, there have been attempts using BERT and sklearn’s SVM-SVC which report accuracy of about 89% and 85% respectively. We will train a state-of-the-art model with accuracy of 91.5% and an F1-score of 87.1%. Note that F1-score is a better measure as the dataset is unbalanced, but as the 2 previous attempts use accuracy as the measure of reporting, therefore we also report accuracy score for comparison.\nThe notebook is structured as follows:\n Setting up the GPU Environment Getting Data Training and Testing the Model Using the Model (Running Inference)  Task Description  Sentiment analysis is the task of classifying the polarity of a given text.\n Setting up the GPU Environment Ensure we have a GPU runtime If you’re running this notebook in Google Colab, select Runtime  Change Runtime Type from the menubar. Ensure that GPU is selected as the Hardware accelerator. This will allow us to use the GPU to train the model subsequently.\nInstall Dependencies and Restart Runtime !pip install -q transformers !pip install -q simpletransformers You might see the error ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible after installing the dependencies. This is normal and caused by the simpletransformers library.\nThe solution to this will be to reset the execution environment now. Go to the menu Runtime  Restart runtime then continue on from the next section to download and process the data.\nGetting Data Pulling the data from Github We pull the data from the ChineseNlpCorpus github repository to a pandas dataframe. We then display the top few rows to check if it has been downloaded correctly with .head().\nimport pandas as pd data_df = pd.read_csv('https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/waimai_10k/waimai_10k.csv', usecols=['label','review']) data_df = data_df.rename(columns={'review': 'text', 'label': 'labels'}) data_df.head() We split the dataset into a training set (80% of the samples) and a test set (20% of the samples). We also choose a fixed value for fixed_random_state so that this split is deterministic (always the same samples).\nWe can then check the dataset properties (6,387 train negative, 3,302 train positive, 1,600 test negative and 798 test positive, an unbalanced dataset). The label 0 is the negative polarity class while 1 is the positive polarity class.\nfrom sklearn.model_selection import train_test_split fixed_random_state = 5 train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=fixed_random_state) data = [[train_df.labels.value_counts()[0], test_df.labels.value_counts()[0]], [train_df.labels.value_counts()[1], test_df.labels.value_counts()[1]]] # Prints out the dataset sizes of train and test sets per label. pd.DataFrame(data, columns=[\"Train\", \"Test\"]) Training and Testing the Model Set up the Training Arguments We set up the training arguments. Here we train to 2 epochs to reduce the training time as much as possible, the BERT article on this dataset trained to 10 epochs but didn’t see much gain in overall accuracy. It is also possible to split out a development set and use that to evaluate for a better model, this 10k dataset is quite small though and we are confident we can get good accuracy with just 2 epochs (we are impatient).\ntrain_args = { 'reprocess_input_data': True, 'overwrite_output_dir': True, 'sliding_window': True, 'max_seq_length': 64, 'num_train_epochs': 2, 'train_batch_size': 128, 'fp16': True, 'output_dir': '/outputs/', } Train the Model Once we have setup the train_args dictionary, the next step would be to train the model. We use the pre-trained mandarin XLNet model, hfl/chinese-xlnet-mid from the awesome Hugging Face Transformers library and model repository as the base and use the Simple Transformers library on top of it to make it so we can train the classification model with just 2 lines of code. The pre-trained mandarin model base we use is by HFL with more details at this repository.\nXLNet is an auto-regressive language model which outputs the joint probability of a sequence of tokens based on the transformer architecture with recurrence. Although its also bigger than BERT and has a (slightly) different architecture, it’s change in training objective is probably the biggest contribution. It’s training objective is to predict each word in a sequence using any combination of other words in that sequence which seems to perform better on ambiguous contexts.\nfrom simpletransformers.classification import ClassificationModel import pandas as pd import logging import sklearn logging.basicConfig(level=logging.DEBUG) transformers_logger = logging.getLogger('transformers') transformers_logger.setLevel(logging.WARNING) # We use the XLNet base cased pre-trained model. model = ClassificationModel('xlnet', 'hfl/chinese-xlnet-mid', num_labels=2, args=train_args) # Train the model, there is no development or validation set for this dataset # https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping model.train_model(train_df) # Evaluate the model in terms of accuracy score result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.f1_score) The F1-score for the model is 87.1%.\nAs mentioned earlier, the class distribution (the number of positive vs negative) is not balanced (not evenly distributed), so F1-score is a better accuracy measure.\nPrevious articles, however, published accuracy on the the test/validation set. Hence, we will also calculate the accuracy score of our model.\nresult, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.accuracy_score) We see that the accuracy score from the model after training for 2 epochs is 91.5% (‘acc’: 0.914512093411176).\n We’ve just trained a new state-of-the-art mandarin sentiment analysis model on the WAIMAI_10K dataset of food delivery reviews!\n Using the Model (Running Inference) Running the model to do some predictions/inference is as simple as calling model.predict(input_list).\nsamples = ['送错地方了，态度还不好，豆腐脑撒的哪都是，本次用餐体验很不好', # food was sent to the wrong place and the attitude was bad... '很不错，服务非常好，很认真'] # really quite good, service was very good, very sincere predictions, _ = model.predict(samples) label_dict = {0: 'negative', 1: 'positive'} for idx, sample in enumerate(samples): print('{} - {}: {}'.format(idx, label_dict[predictions[idx]], sample)) We can connect to Google Drive with the following code to save any files you want to persist. You can also click the Files icon on the left panel and click Mount Drive to mount your Google Drive.\nThe root of your Google Drive will be mounted to /content/drive/My Drive/. If you have problems mounting the drive, you can check out this tutorial.\nfrom google.colab import drive drive.mount('/content/drive/') You can move the model checkpount files which are saved in the /outputs/ directory to your Google Drive.\nimport shutil shutil.move('/outputs/', \"/content/drive/My Drive/outputs/\") More Such Notebooks Visit or star the eugenesiow/practical-ml repository on Github for more such notebooks:\n AI Glossary in Mandarin Visit or star the eugenesiow/ai-glossary-mandarin repository on Github if you need an English-to-Mandarin dictionary of AI terminology grouped topically by areas (e.g. NLP) and tasks (e.g. NER):\n Alternatives to Colab Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:\n Google Colab vs Paperspace Gradient  ","wordCount":"1196","inLanguage":"en","image":"https://news.machinelearning.sg/sa_mandarin.png","datePublished":"2020-12-23T10:00:00+08:00","dateModified":"2020-12-23T10:00:00+08:00","author":{"@type":"Person","name":"Eugene"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/"},"publisher":{"@type":"Organization","name":"News @ machinelearning.sg","logo":{"@type":"ImageObject","url":"https://news.machinelearning.sg/favicon.ico"}}}</script><script async data-id=defa0fb0-3f27-4afe-b567-4f57d47c86e9 src=https://tinyads.io/e></script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://news.machinelearning.sg/ accesskey=h>News</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span><span class=lang-switch><ul><li><a href=https://machinelearning.sg>machinelearning.sg</a></li></ul></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://news.machinelearning.sg/about/><span>About</span></a></li><li><a href=https://news.machinelearning.sg/archives/><span>Archive</span></a></li><li><a href=https://news.machinelearning.sg/tags/><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Sentiment Analysis in Mandarin with XLNet</h1><div class=post-meta>December 23, 2020&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Eugene</div></header><figure class=entry-cover><img srcset="https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin_hu504cb7d17fbf0ba0d5fe3ea2c231775f_1757297_360x0_resize_box_2.png 360w ,https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin_hu504cb7d17fbf0ba0d5fe3ea2c231775f_1757297_480x0_resize_box_2.png 480w ,https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin_hu504cb7d17fbf0ba0d5fe3ea2c231775f_1757297_720x0_resize_box_2.png 720w ,https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin_hu504cb7d17fbf0ba0d5fe3ea2c231775f_1757297_1080x0_resize_box_2.png 1080w ,https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin.png 1476w" sizes="(min-width: 768px) 720px, 100vw" src=https://news.machinelearning.sg/posts/sentiment_analysis_in_mandarin_with_xlnet/sa_mandarin.png alt="Sentiment Analysis in Mandarin on Food Delivery Reviews"></figure><div class=toc><details><summary><div class=details accesskey=c>Table of Contents</div></summary><blockquote><ul><li><a href=#practical-machine-learning---learn-step-by-step-to-train-a-model aria-label="Practical Machine Learning - Learn Step-by-Step to Train a Model">Practical Machine Learning - Learn Step-by-Step to Train a Model</a></li><li><a href=#sentiment-analysis-in-mandarin-on-food-delivery-reviews-%e6%83%85%e6%84%9f%e5%88%86%e6%9e%90 aria-label="Sentiment Analysis in Mandarin on Food Delivery Reviews, 情感分析">Sentiment Analysis in Mandarin on Food Delivery Reviews, 情感分析</a><ul><ul><li><a href=#task-description aria-label="Task Description">Task Description</a></li></ul></ul></li><li><a href=#setting-up-the-gpu-environment aria-label="Setting up the GPU Environment">Setting up the GPU Environment</a><ul><ul><li><a href=#ensure-we-have-a-gpu-runtime aria-label="Ensure we have a GPU runtime">Ensure we have a GPU runtime</a></li><li><a href=#install-dependencies-and-restart-runtime aria-label="Install Dependencies and Restart Runtime">Install Dependencies and Restart Runtime</a></li></ul></ul></li><li><a href=#getting-data aria-label="Getting Data">Getting Data</a><ul><ul><li><a href=#pulling-the-data-from-github aria-label="Pulling the data from Github">Pulling the data from Github</a></li></ul></ul></li><li><a href=#training-and-testing-the-model aria-label="Training and Testing the Model">Training and Testing the Model</a><ul><ul><li><a href=#set-up-the-training-arguments aria-label="Set up the Training Arguments">Set up the Training Arguments</a></li><li><a href=#train-the-model aria-label="Train the Model">Train the Model</a></li></ul></ul></li><li><a href=#using-the-model-running-inference aria-label="Using the Model (Running Inference)">Using the Model (Running Inference)</a></li><li><a href=#more-such-notebooks aria-label="More Such Notebooks">More Such Notebooks</a></li><li><a href=#ai-glossary-in-mandarin aria-label="AI Glossary in Mandarin">AI Glossary in Mandarin</a></li><li><a href=#alternatives-to-colab aria-label="Alternatives to Colab">Alternatives to Colab</a></li></ul></blockquote></details></div><div class=post-content><blockquote><p><strong>tl;dr</strong> A step-by-step tutorial to train a state-of-the-art model for sentiment analysis on mandarin food delivery
reviews using the XLNet architecture. We will use Google Colab&rsquo;s free Jupyter Notebook in the cloud.</p></blockquote><h2 id=practical-machine-learning---learn-step-by-step-to-train-a-model>Practical Machine Learning - Learn Step-by-Step to Train a Model<a hidden class=anchor aria-hidden=true href=#practical-machine-learning---learn-step-by-step-to-train-a-model>#</a></h2><p>A great way to learn is by going step-by-step through the process of training and evaluating the model.</p><p>Hit the <strong><code>Open in Colab</code></strong> button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough.
<a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sentiment_Analysis_Mandarin_Food_Reviews.ipynb title="Open in Colab"><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Continue on if you prefer reading the code here.</p><h2 id=sentiment-analysis-in-mandarin-on-food-delivery-reviews-情感分析>Sentiment Analysis in Mandarin on Food Delivery Reviews, 情感分析<a hidden class=anchor aria-hidden=true href=#sentiment-analysis-in-mandarin-on-food-delivery-reviews-情感分析>#</a></h2><p><a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sentiment_Analysis_Mandarin_Food_Reviews.ipynb title="Open in Colab"><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Notebook to train a mandarin XLNet model to perform sentiment analysis. The <a href=https://github.com/SophonPlus/ChineseNlpCorpus#%E6%83%85%E6%84%9F%E8%A7%82%E7%82%B9%E8%AF%84%E8%AE%BA-%E5%80%BE%E5%90%91%E6%80%A7%E5%88%86%E6%9E%90>dataset</a> used is the unbalanced WAIMAI_10K (10,000 food delivery reviews from a food delivery platform in China). The dataset has binary labels: <strong><code>postive</code></strong> or <strong><code>negative</code></strong>. There is no published state-of-the-art model that we know of on this dataset, however, there have been attempts using <a href=https://github.com/BruceJust/Sentiment-classification-by-BERT>BERT</a> and sklearn&rsquo;s <a href=https://www.programmersought.com/article/48933926195/>SVM-SVC</a> which report accuracy of about 89% and 85% respectively. We will train a state-of-the-art model with accuracy of 91.5% and an F1-score of 87.1%. Note that F1-score is a better measure as the dataset is unbalanced, but as the 2 previous attempts use accuracy as the measure of reporting, therefore we also report accuracy score for comparison.</p><p>The notebook is structured as follows:</p><ul><li>Setting up the GPU Environment</li><li>Getting Data</li><li>Training and Testing the Model</li><li>Using the Model (Running Inference)</li></ul><h4 id=task-description>Task Description<a hidden class=anchor aria-hidden=true href=#task-description>#</a></h4><blockquote><p>Sentiment analysis is the task of classifying the polarity of a given text.</p></blockquote><h2 id=setting-up-the-gpu-environment>Setting up the GPU Environment<a hidden class=anchor aria-hidden=true href=#setting-up-the-gpu-environment>#</a></h2><h4 id=ensure-we-have-a-gpu-runtime>Ensure we have a GPU runtime<a hidden class=anchor aria-hidden=true href=#ensure-we-have-a-gpu-runtime>#</a></h4><p>If you&rsquo;re running this notebook in Google Colab, select <code>Runtime</code> > <code>Change Runtime Type</code> from the menubar. Ensure that <code>GPU</code> is selected as the <code>Hardware accelerator</code>. This will allow us to use the GPU to train the model subsequently.</p><h4 id=install-dependencies-and-restart-runtime>Install Dependencies and Restart Runtime<a hidden class=anchor aria-hidden=true href=#install-dependencies-and-restart-runtime>#</a></h4><pre><code>!pip install -q transformers
!pip install -q simpletransformers
</code></pre><p>You might see the error <code>ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible</code> after installing the dependencies. <strong>This is normal</strong> and caused by the <code>simpletransformers</code> library.</p><p>The <strong>solution</strong> to this will be to <strong>reset the execution environment</strong> now. Go to the menu <code>Runtime</code> > <code>Restart runtime</code> then continue on from the next section to download and process the data.</p><h2 id=getting-data>Getting Data<a hidden class=anchor aria-hidden=true href=#getting-data>#</a></h2><h4 id=pulling-the-data-from-github>Pulling the data from Github<a hidden class=anchor aria-hidden=true href=#pulling-the-data-from-github>#</a></h4><p>We pull the data from the <a href=https://github.com/SophonPlus/ChineseNlpCorpus#%E6%83%85%E6%84%9F%E8%A7%82%E7%82%B9%E8%AF%84%E8%AE%BA-%E5%80%BE%E5%90%91%E6%80%A7%E5%88%86%E6%9E%90>ChineseNlpCorpus</a> github repository to a <code>pandas</code> dataframe. We then display the top few rows to check if it has been downloaded correctly with <code>.head()</code>.</p><pre><code>import pandas as pd
data_df = pd.read_csv('https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/waimai_10k/waimai_10k.csv', usecols=['label','review'])
data_df = data_df.rename(columns={'review': 'text', 'label': 'labels'})
data_df.head()
</code></pre><p>We split the dataset into a training set (80% of the samples) and a test set (20% of the samples). We also choose a fixed value for <code>fixed_random_state</code> so that this split is deterministic (always the same samples).</p><p>We can then check the dataset properties (6,387 train negative, 3,302 train positive, 1,600 test negative and 798 test positive, an unbalanced dataset). The label <strong><code>0</code></strong> is the <strong><code>negative</code></strong> polarity class while <strong><code>1</code></strong> is the <strong><code>positive</code></strong> polarity class.</p><pre><code>from sklearn.model_selection import train_test_split
fixed_random_state = 5
train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=fixed_random_state)

data = [[train_df.labels.value_counts()[0], test_df.labels.value_counts()[0]], 
        [train_df.labels.value_counts()[1], test_df.labels.value_counts()[1]]]

# Prints out the dataset sizes of train and test sets per label.
pd.DataFrame(data, columns=[&quot;Train&quot;, &quot;Test&quot;])
</code></pre><h2 id=training-and-testing-the-model>Training and Testing the Model<a hidden class=anchor aria-hidden=true href=#training-and-testing-the-model>#</a></h2><h4 id=set-up-the-training-arguments>Set up the Training Arguments<a hidden class=anchor aria-hidden=true href=#set-up-the-training-arguments>#</a></h4><p>We set up the training arguments. Here we train to 2 epochs to reduce the training time as much as possible, the BERT article on this dataset trained to 10 epochs but didn&rsquo;t see much gain in overall accuracy. It is also possible to split out a development set and use that to evaluate for a better model, this 10k dataset is quite small though and we are confident we can get good accuracy with just 2 epochs (we are impatient).</p><pre><code>train_args = {
    'reprocess_input_data': True,
    'overwrite_output_dir': True,
    'sliding_window': True,
    'max_seq_length': 64,
    'num_train_epochs': 2,
    'train_batch_size': 128,
    'fp16': True,
    'output_dir': '/outputs/',
}
</code></pre><h4 id=train-the-model>Train the Model<a hidden class=anchor aria-hidden=true href=#train-the-model>#</a></h4><p>Once we have setup the <code>train_args</code> dictionary, the next step would be to train the model. We use the pre-trained mandarin XLNet model, <a href=https://huggingface.co/hfl/chinese-xlnet-mid><code>hfl/chinese-xlnet-mid</code></a> from the awesome <a href=https://github.com/huggingface/transformers>Hugging Face Transformers</a> library and model repository as the base and use the <a href=https://simpletransformers.ai/docs/classification-models/>Simple Transformers library</a> on top of it to make it so we can train the classification model with just 2 lines of code. The pre-trained mandarin model base we use is by <a href=https://huggingface.co/hfl>HFL</a> with more details at this <a href=https://github.com/ymcui/Chinese-XLNet>repository</a>.</p><p><a href=https://arxiv.org/pdf/1906.08237.pdf>XLNet</a> is an auto-regressive language model which outputs the joint probability of a sequence of tokens based on the transformer architecture with recurrence. Although its also bigger than BERT and has a (slightly) different architecture, it&rsquo;s change in training objective is probably the biggest contribution. It&rsquo;s training objective is to predict each word in a sequence using any combination of other words in that sequence which seems to perform better on ambiguous contexts.</p><pre><code>from simpletransformers.classification import ClassificationModel
import pandas as pd
import logging
import sklearn

logging.basicConfig(level=logging.DEBUG)
transformers_logger = logging.getLogger('transformers')
transformers_logger.setLevel(logging.WARNING)

# We use the XLNet base cased pre-trained model.
model = ClassificationModel('xlnet', 'hfl/chinese-xlnet-mid', num_labels=2, args=train_args) 

# Train the model, there is no development or validation set for this dataset 
# https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping
model.train_model(train_df)

# Evaluate the model in terms of accuracy score
result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.f1_score)
</code></pre><p>The F1-score for the model is <strong>87.1%</strong>.</p><p>As mentioned earlier, the class distribution (the number of <strong><code>positive</code></strong> vs <strong><code>negative</code></strong>) is not balanced (not evenly distributed), so <a href=https://sebastianraschka.com/faq/docs/computing-the-f1-score.html>F1-score is a better accuracy measure</a>.</p><p>Previous articles, however, published accuracy on the the test/validation set. Hence, we will also calculate the accuracy score of our model.</p><pre><code>result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.accuracy_score)
</code></pre><p>We see that the accuracy score from the model after training for 2 epochs is <strong>91.5%</strong> (&lsquo;acc&rsquo;: 0.914512093411176).</p><blockquote><p>We&rsquo;ve just trained a new state-of-the-art mandarin sentiment analysis model on the WAIMAI_10K dataset of food delivery reviews!</p></blockquote><h2 id=using-the-model-running-inference>Using the Model (Running Inference)<a hidden class=anchor aria-hidden=true href=#using-the-model-running-inference>#</a></h2><p>Running the model to do some predictions/inference is as simple as calling <code>model.predict(input_list)</code>.</p><pre><code>samples = ['送错地方了，态度还不好，豆腐脑撒的哪都是，本次用餐体验很不好', # food was sent to the wrong place and the attitude was bad...
           '很不错，服务非常好，很认真'] # really quite good, service was very good, very sincere
predictions, _ = model.predict(samples)
label_dict = {0: 'negative', 1: 'positive'}
for idx, sample in enumerate(samples):
  print('{} - {}: {}'.format(idx, label_dict[predictions[idx]], sample))
</code></pre><p>We can connect to Google Drive with the following code to save any files you want to persist. You can also click the <code>Files</code> icon on the left panel and click <code>Mount Drive</code> to mount your Google Drive.</p><p>The root of your Google Drive will be mounted to <code>/content/drive/My Drive/</code>. If you have problems mounting the drive, you can check out this <a href=https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166>tutorial</a>.</p><pre><code>from google.colab import drive
drive.mount('/content/drive/')
</code></pre><p>You can move the model checkpount files which are saved in the <code>/outputs/</code> directory to your Google Drive.</p><pre><code>import shutil
shutil.move('/outputs/', &quot;/content/drive/My Drive/outputs/&quot;)
</code></pre><h2 id=more-such-notebooks>More Such Notebooks<a hidden class=anchor aria-hidden=true href=#more-such-notebooks>#</a></h2><p>Visit or star the <a href=https://github.com/eugenesiow/practical-ml>eugenesiow/practical-ml</a> repository on Github for more such notebooks:</p><iframe src="https://ghbtns.com/github-btn.html?user=eugenesiow&repo=practical-ml&type=star&count=true&size=large" frameborder=0 scrolling=0 width=170 height=30 title="Practical Machine Learning"></iframe><h2 id=ai-glossary-in-mandarin>AI Glossary in Mandarin<a hidden class=anchor aria-hidden=true href=#ai-glossary-in-mandarin>#</a></h2><p>Visit or star the <a href=https://github.com/eugenesiow/ai-glossary-mandarin>eugenesiow/ai-glossary-mandarin</a> repository on
Github if you need an English-to-Mandarin dictionary of AI terminology grouped topically by areas (e.g. NLP) and tasks (e.g. NER):</p><iframe src="https://ghbtns.com/github-btn.html?user=eugenesiow&repo=ai-glossary-mandarin&type=star&count=true&size=large" frameborder=0 scrolling=0 width=170 height=30 title="AI Glossary in Mandarin"></iframe><h2 id=alternatives-to-colab>Alternatives to Colab<a hidden class=anchor aria-hidden=true href=#alternatives-to-colab>#</a></h2><p>Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:</p><ul><li><a href=https://news.machinelearning.sg/posts/google_colab_vs_paperspace_gradient/>Google Colab vs Paperspace Gradient</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://news.machinelearning.sg/tags/natural-language-processing>Natural Language Processing</a></li><li><a href=https://news.machinelearning.sg/tags/deep-learning>Deep Learning</a></li><li><a href=https://news.machinelearning.sg/tags/machine-learning>Machine Learning</a></li><li><a href=https://news.machinelearning.sg/tags/gpu>GPU</a></li><li><a href=https://news.machinelearning.sg/tags/source-code>Source Code</a></li><li><a href=https://news.machinelearning.sg/tags/pytorch>PyTorch</a></li><li><a href=https://news.machinelearning.sg/tags/sentiment-analysis>Sentiment Analysis</a></li><li><a href=https://news.machinelearning.sg/tags/jupyter-notebook>Jupyter Notebook</a></li><li><a href=https://news.machinelearning.sg/tags/colab>Colab</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on twitter" href="https://twitter.com/intent/tweet/?text=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f&hashtags=NaturalLanguageProcessing%2cDeepLearning%2cMachineLearning%2cGPU%2cSourceCode%2cPyTorch%2cSentimentAnalysis%2cJupyterNotebook%2cColab"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f&title=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet&summary=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet&source=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f&title=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on whatsapp" href="https://api.whatsapp.com/send?text=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet%20-%20https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis in Mandarin with XLNet on telegram" href="https://telegram.me/share/url?text=Sentiment%20Analysis%20in%20Mandarin%20with%20XLNet&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_in_mandarin_with_xlnet%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://news.machinelearning.sg/>News @ machinelearning.sg</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=https://news.machinelearning.sg/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>