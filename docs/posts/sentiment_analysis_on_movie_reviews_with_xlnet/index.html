<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Sentiment Analysis on Movie Reviews with XLNet | News @ machinelearning.sg</title><meta name=keywords content="Natural Language Processing,Deep Learning,Machine Learning,GPU,Source Code,PyTorch,Sentiment Analysis,Jupyter Notebook,Colab"><meta name=description content="tl;dr A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews with XLNet using a free Jupyter Notebook in the cloud.
The IMDB Movie Reviews Dataset and XLNet The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment analysis performance. It&rsquo;s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset, making it a very nice dataset for benchmarking on."><meta name=author content="Eugene"><link rel=canonical href=https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://news.machinelearning.sg/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://news.machinelearning.sg/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://news.machinelearning.sg/favicon-32x32.png><link rel=apple-touch-icon href=https://news.machinelearning.sg/apple-touch-icon.png><link rel=mask-icon href=https://news.machinelearning.sg/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-185405110-1","auto"),ga("send","pageview"))</script><meta property="og:title" content="Sentiment Analysis on Movie Reviews with XLNet"><meta property="og:description" content="tl;dr A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews with XLNet using a free Jupyter Notebook in the cloud.
The IMDB Movie Reviews Dataset and XLNet The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment analysis performance. It&rsquo;s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset, making it a very nice dataset for benchmarking on."><meta property="og:type" content="article"><meta property="og:url" content="https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/"><meta property="og:image" content="https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-12-22T16:00:00+08:00"><meta property="article:modified_time" content="2020-12-22T16:00:00+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies.png"><meta name=twitter:title content="Sentiment Analysis on Movie Reviews with XLNet"><meta name=twitter:description content="tl;dr A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews with XLNet using a free Jupyter Notebook in the cloud.
The IMDB Movie Reviews Dataset and XLNet The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment analysis performance. It&rsquo;s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset, making it a very nice dataset for benchmarking on."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://news.machinelearning.sg/posts/"},{"@type":"ListItem","position":2,"name":"Sentiment Analysis on Movie Reviews with XLNet","item":"https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Sentiment Analysis on Movie Reviews with XLNet","name":"Sentiment Analysis on Movie Reviews with XLNet","description":"tl;dr A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews with XLNet using a free Jupyter Notebook in the cloud.\nThe IMDB Movie Reviews Dataset and XLNet The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment analysis performance. It\u0026rsquo;s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset, making it a very nice dataset for benchmarking on.","keywords":["Natural Language Processing","Deep Learning","Machine Learning","GPU","Source Code","PyTorch","Sentiment Analysis","Jupyter Notebook","Colab"],"articleBody":" tl;dr A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews with XLNet using a free Jupyter Notebook in the cloud.\nThe IMDB Movie Reviews Dataset and XLNet The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment analysis performance. It’s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset, making it a very nice dataset for benchmarking on.\nThe model with state-of-the-art performance on this dataset is XLNet, Yang et al. (2019), which has an accuracy of 96.2%. In this practical, we train a an XLNet base model to just 1 epoch (training more epochs to minimise loss gives higher performance, but we are impatient in a practical). We get an accuracy of 92.2% due to these limitations, which is still pretty decent.\nPractical Machine Learning - Learn Step-by-Step to Train a Model A great way to learn is by going step-by-step through the process of training and evaluating the model.\nHit the Open in Colab button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough. Continue on if you prefer reading the code here.\nSentiment Analysis on IMDB Movie Reviews Notebook to train an XLNet model to perform sentiment analysis. The dataset used is a balanced collection of (50,000 - 1:1 train-test ratio) IMDB movie reviews with binary labels: postive or negative from the paper by Maas et al. (2011). The current state-of-the-art model on this dataset is XLNet by Yang et al. (2019) which has an accuracy of 96.2%. We get an accuracy of 92.2% due to the limitations of GPU memory on Colab (we use XLNet base instead of the large model), train to 1 epoch only for speed and we are unable to replicate all the hyperparameters (sequence length).\nThe notebook is structured as follows:\nSetting up the GPU Environment Getting Data Training and Testing the Model Using the Model (Running Inference) Task Description Sentiment analysis is the task of classifying the polarity of a given text.\nSetting up the GPU Environment Ensure we have a GPU runtime If you’re running this notebook in Google Colab, select Runtime \u003e Change Runtime Type from the menubar. Ensure that GPU is selected as the Hardware accelerator. This will allow us to use the GPU to train the model subsequently.\nInstall Dependencies and Restart Runtime !pip install -q transformers !pip install -q simpletransformers !pip install -q datasets You might see the error ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible after installing the dependencies. This is normal and caused by the simpletransformers library.\nThe solution to this will be to reset the execution environment now. Go to the menu Runtime \u003e Restart runtime then continue on from the next section to download and process the data.\nGetting Data Dataset Description The IMDb dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative (this is the polarity). The dataset contains of an even number of positive and negative reviews (balanced). Only highly polarizing reviews are considered. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. No more than 30 reviews are included per movie. There are 25,000 highly polar movie reviews for training, and 25,000 for testing.\nPulling the data from huggingface/datasets We use Hugging Face’s awesome datasets library to get the pre-processed version of the original IMDB dataset.\nThe code below pulls the train and test datasets from huggingface/datasets using load_dataset('imdb') and transform them into pandas dataframes for use with the simpletransformers library to train the model.\nimport pandas as pd from datasets import load_dataset dataset_train = load_dataset('imdb',split='train') dataset_train.rename_column_('label', 'labels') train_df=pd.DataFrame(dataset_train) dataset_test = load_dataset('imdb',split='test') dataset_test.rename_column_('label', 'labels') test_df=pd.DataFrame(dataset_test) Once done we can take a look at the head() of the training set to check if our data has been retrieved properly.\ntrain_df.head() We also double check the dataset properties are exactly the same as those reported in the papers (25,000 train, 25,000 test size, balanced). 0 is the negative polarity class while 1 is the positive polarity class.\ndata = [[train_df.labels.value_counts()[0], test_df.labels.value_counts()[0]], [train_df.labels.value_counts()[1], test_df.labels.value_counts()[1]]] # Prints out the dataset sizes of train test and validate as per the table. pd.DataFrame(data, columns=[\"Train\", \"Test\"]) Training and Testing the Model Set the Hyperparmeters First we setup the hyperparamters, using the hyperparemeters specified in the Yang et al. (2019) paper whenever possible (we take Yelp hyperparameters as IMDB ones are not specified). The comparison of hyperparameters is shown in the table below. The major difference is due to GPU memory limitations we are unable to use a sequence length of 512, instead we use a sliding window on a sequence length of 64. We also train to 1 epoch only as want the training to complete fast.\nParameter Ours Paper Epochs 1 ? Batch Size 128 128 Seq Length 64 512 Learning Rate 1e-5 1e-5 Weight decay 1e-2 1e-2 train_args = { 'reprocess_input_data': True, 'overwrite_output_dir': True, 'sliding_window': True, 'max_seq_length': 64, 'num_train_epochs': 1, 'learning_rate': 0.00001, 'weight_decay': 0.01, 'train_batch_size': 128, 'fp16': True, 'output_dir': '/outputs/', } Train the Model Once we have setup the hyperparemeters in the train_args dictionary, the next step would be to train the model. We use the xlnet-base-cased model from the awesome Hugging Face Transformers library and use the Simple Transformers library on top of it to make it so we can train the classification model with just 2 lines of code.\nXLNet is an auto-regressive language model which outputs the joint probability of a sequence of tokens based on the transformer architecture with recurrence. Although its also bigger than BERT and has a (slightly) different architecture, it’s change in training objective is probably the biggest contribution. It’s training objective is to predict each word in a sequence using any combination of other words in that sequence which seems to perform better on ambiguous contexts.\nfrom simpletransformers.classification import ClassificationModel import pandas as pd import logging import sklearn logging.basicConfig(level=logging.DEBUG) transformers_logger = logging.getLogger('transformers') transformers_logger.setLevel(logging.WARNING) # We use the XLNet base cased pre-trained model. model = ClassificationModel('xlnet', 'xlnet-base-cased', num_labels=2, args=train_args) # Train the model, there is no development or validation set for this dataset # https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping model.train_model(train_df) # Evaluate the model in terms of accuracy score result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.accuracy_score) We see that the output accuracy from the model after training for 1 epoch is 92.2% (‘acc’: 0.92156).\nUsing the Model (Running Inference) Running the model to do some predictions/inference is as simple as calling model.predict(input_list).\nsamples = ['The script is nice.Though the casting is absolutely non-watchable.No style. the costumes do not look like some from the High Highbury society. Comparing Gwyneth Paltrow with Kate Beckinsale I can only say that Ms. Beckinsale speaks British English better than Ms. Paltrow, though in Ms. Paltrow\\'s acting lies the very nature of Emma Woodhouse. Mr. Northam undoubtedly is the best Mr. Knightley of all versions, he is romantic and not at all sharp-looking and unfeeling like Mr. Knightley in the TV-version. P.S.The spectator cannot see at all Mr. Elton-Ms. Smith relationship\\'s development as it was in the motion version, so one cannot understand where was all Emma\\'s trying of make a Elton-Smith match (besides of the portrait).'] predictions, _ = model.predict(samples) label_dict = {0: 'negative', 1: 'positive'} for idx, sample in enumerate(samples): print('{} - {}: {}'.format(idx, label_dict[predictions[idx]], sample)) We can connect to Google Drive with the following code to save any files you want to persist. You can also click the Files icon on the left panel and click Mount Drive to mount your Google Drive.\nThe root of your Google Drive will be mounted to /content/drive/My Drive/. If you have problems mounting the drive, you can check out this tutorial.\nfrom google.colab import drive drive.mount('/content/drive/') You can move the model checkpount files which are saved in the /outputs/ directory to your Google Drive.\nimport shutil shutil.move('/outputs/', \"/content/drive/My Drive/outputs/\") More Such Notebooks Visit or star the eugenesiow/practical-ml repository on Github for more such notebooks:\nAlternatives to Colab Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:\nGoogle Colab vs Paperspace Gradient ","wordCount":"1364","inLanguage":"en","image":"https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies.png","datePublished":"2020-12-22T16:00:00+08:00","dateModified":"2020-12-22T16:00:00+08:00","author":{"@type":"Person","name":"Eugene"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/"},"publisher":{"@type":"Organization","name":"News @ machinelearning.sg","logo":{"@type":"ImageObject","url":"https://news.machinelearning.sg/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://news.machinelearning.sg/ accesskey=h title="News @ machinelearning.sg (Alt + H)">News @ machinelearning.sg</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://news.machinelearning.sg/about/ title=About><span>About</span></a></li><li><a href=https://news.machinelearning.sg/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://news.machinelearning.sg/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Sentiment Analysis on Movie Reviews with XLNet</h1><div class=post-meta><span title='2020-12-22 16:00:00 +0800 +08'>December 22, 2020</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Eugene</div></header><figure class=entry-cover><img loading=lazy srcset="https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies_hua2565a2bed97be0cc877e9b5a6f3b9be_488119_360x0_resize_box_3.png 360w ,https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies_hua2565a2bed97be0cc877e9b5a6f3b9be_488119_480x0_resize_box_3.png 480w ,https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies_hua2565a2bed97be0cc877e9b5a6f3b9be_488119_720x0_resize_box_3.png 720w ,https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies_hua2565a2bed97be0cc877e9b5a6f3b9be_488119_1080x0_resize_box_3.png 1080w ,https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies.png 1477w" sizes="(min-width: 768px) 720px, 100vw" src=https://news.machinelearning.sg/posts/sentiment_analysis_on_movie_reviews_with_xlnet/sentiment_analysis_movies.png alt="Sentiment Analysis on Movie Reviews" width=1477 height=984></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#the-imdb-movie-reviews-dataset-and-xlnet aria-label="The IMDB Movie Reviews Dataset and XLNet">The IMDB Movie Reviews Dataset and XLNet</a></li><li><a href=#practical-machine-learning---learn-step-by-step-to-train-a-model aria-label="Practical Machine Learning - Learn Step-by-Step to Train a Model">Practical Machine Learning - Learn Step-by-Step to Train a Model</a></li><li><a href=#sentiment-analysis-on-imdb-movie-reviews aria-label="Sentiment Analysis on IMDB Movie Reviews">Sentiment Analysis on IMDB Movie Reviews</a><ul><ul><li><a href=#task-description aria-label="Task Description">Task Description</a></li></ul></ul></li><li><a href=#setting-up-the-gpu-environment aria-label="Setting up the GPU Environment">Setting up the GPU Environment</a><ul><ul><li><a href=#ensure-we-have-a-gpu-runtime aria-label="Ensure we have a GPU runtime">Ensure we have a GPU runtime</a></li><li><a href=#install-dependencies-and-restart-runtime aria-label="Install Dependencies and Restart Runtime">Install Dependencies and Restart Runtime</a></li></ul></ul></li><li><a href=#getting-data aria-label="Getting Data">Getting Data</a><ul><ul><li><a href=#dataset-description aria-label="Dataset Description">Dataset Description</a></li><li><a href=#pulling-the-data-from-huggingfacedatasets aria-label="Pulling the data from huggingface/datasets">Pulling the data from <code>huggingface/datasets</code></a></li></ul></ul></li><li><a href=#training-and-testing-the-model aria-label="Training and Testing the Model">Training and Testing the Model</a><ul><ul><li><a href=#set-the-hyperparmeters aria-label="Set the Hyperparmeters">Set the Hyperparmeters</a></li><li><a href=#train-the-model aria-label="Train the Model">Train the Model</a></li></ul></ul></li><li><a href=#using-the-model-running-inference aria-label="Using the Model (Running Inference)">Using the Model (Running Inference)</a></li><li><a href=#more-such-notebooks aria-label="More Such Notebooks">More Such Notebooks</a></li><li><a href=#alternatives-to-colab aria-label="Alternatives to Colab">Alternatives to Colab</a></li></ul></div></details></div><div class=post-content><blockquote><p><strong>tl;dr</strong> A step-by-step tutorial to train a sentiment analysis model to classify polarity of IMDB movie reviews
with XLNet using a free Jupyter Notebook in the cloud.</p></blockquote><h2 id=the-imdb-movie-reviews-dataset-and-xlnet>The IMDB Movie Reviews Dataset and XLNet<a hidden class=anchor aria-hidden=true href=#the-imdb-movie-reviews-dataset-and-xlnet>#</a></h2><p>The Internet Movie Database (IMDb) movie reviews dataset is a very well-established benchmark (since 2011) for sentiment
analysis performance. It&rsquo;s probably the first large-ish (50,000 train+test), balanced sentiment analysis dataset,
making it a very nice dataset for benchmarking on.</p><p>The model with state-of-the-art performance on this dataset is XLNet, <a href=https://arxiv.org/pdf/1906.08237.pdf>Yang et al. (2019)</a>,
which has an accuracy of <a href=http://nlpprogress.com/english/sentiment_analysis.html>96.2%</a>. In this practical, we train a
an XLNet base model to just 1 epoch (training more epochs to minimise loss gives higher performance, but we are impatient
in a practical). We get an accuracy of 92.2% due to these limitations, which is still pretty decent.</p><h2 id=practical-machine-learning---learn-step-by-step-to-train-a-model>Practical Machine Learning - Learn Step-by-Step to Train a Model<a hidden class=anchor aria-hidden=true href=#practical-machine-learning---learn-step-by-step-to-train-a-model>#</a></h2><p>A great way to learn is by going step-by-step through the process of training and evaluating the model.</p><p>Hit the <strong><code>Open in Colab</code></strong> button below to launch a Jupyter Notebook in the cloud with a step-by-step walkthrough.
<a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sentiment_Analysis_Movie_Reviews.ipynb title="Open in Colab"><img loading=lazy src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Continue on if you prefer reading the code here.</p><h2 id=sentiment-analysis-on-imdb-movie-reviews>Sentiment Analysis on IMDB Movie Reviews<a hidden class=anchor aria-hidden=true href=#sentiment-analysis-on-imdb-movie-reviews>#</a></h2><p><a href=https://colab.research.google.com/github/eugenesiow/practical-ml/blob/master/notebooks/Sentiment_Analysis_Movie_Reviews.ipynb title="Open in Colab"><img loading=lazy src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p><p>Notebook to train an XLNet model to perform sentiment analysis. The <a href=https://ai.stanford.edu/~amaas/data/sentiment/>dataset</a> used is a balanced collection of (50,000 - 1:1 train-test ratio) IMDB movie reviews with binary labels: <strong><code>postive</code></strong> or <strong><code>negative</code></strong> from the paper by <a href=https://ai.stanford.edu/~ang/papers/acl11-WordVectorsSentimentAnalysis.pdf>Maas et al. (2011)</a>. The current state-of-the-art model on this dataset is XLNet by <a href=https://arxiv.org/pdf/1906.08237.pdf>Yang et al. (2019)</a> which has an accuracy of <a href=http://nlpprogress.com/english/sentiment_analysis.html>96.2%</a>. We get an accuracy of 92.2% due to the limitations of GPU memory on Colab (we use XLNet base instead of the large model), train to 1 epoch only for speed and we are unable to replicate all the hyperparameters (sequence length).</p><p>The notebook is structured as follows:</p><ul><li>Setting up the GPU Environment</li><li>Getting Data</li><li>Training and Testing the Model</li><li>Using the Model (Running Inference)</li></ul><h4 id=task-description>Task Description<a hidden class=anchor aria-hidden=true href=#task-description>#</a></h4><blockquote><p>Sentiment analysis is the task of classifying the polarity of a given text.</p></blockquote><h2 id=setting-up-the-gpu-environment>Setting up the GPU Environment<a hidden class=anchor aria-hidden=true href=#setting-up-the-gpu-environment>#</a></h2><h4 id=ensure-we-have-a-gpu-runtime>Ensure we have a GPU runtime<a hidden class=anchor aria-hidden=true href=#ensure-we-have-a-gpu-runtime>#</a></h4><p>If you&rsquo;re running this notebook in Google Colab, select <code>Runtime</code> > <code>Change Runtime Type</code> from the menubar. Ensure that <code>GPU</code> is selected as the <code>Hardware accelerator</code>. This will allow us to use the GPU to train the model subsequently.</p><h4 id=install-dependencies-and-restart-runtime>Install Dependencies and Restart Runtime<a hidden class=anchor aria-hidden=true href=#install-dependencies-and-restart-runtime>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>!pip install -q transformers
</span></span><span style=display:flex><span>!pip install -q simpletransformers
</span></span><span style=display:flex><span>!pip install -q datasets
</span></span></code></pre></div><p>You might see the error <code>ERROR: google-colab X.X.X has requirement ipykernel~=X.X, but you'll have ipykernel X.X.X which is incompatible</code> after installing the dependencies. <strong>This is normal</strong> and caused by the <code>simpletransformers</code> library.</p><p>The <strong>solution</strong> to this will be to <strong>reset the execution environment</strong> now. Go to the menu <code>Runtime</code> > <code>Restart runtime</code> then continue on from the next section to download and process the data.</p><h2 id=getting-data>Getting Data<a hidden class=anchor aria-hidden=true href=#getting-data>#</a></h2><h4 id=dataset-description>Dataset Description<a hidden class=anchor aria-hidden=true href=#dataset-description>#</a></h4><p>The IMDb dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative (this is the polarity). The dataset contains of an even number of positive and negative reviews (balanced). Only highly polarizing reviews are considered. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. No more than 30 reviews are included per movie. There are 25,000 highly polar movie reviews for training, and 25,000 for testing.</p><h4 id=pulling-the-data-from-huggingfacedatasets>Pulling the data from <code>huggingface/datasets</code><a hidden class=anchor aria-hidden=true href=#pulling-the-data-from-huggingfacedatasets>#</a></h4><p>We use Hugging Face&rsquo;s awesome datasets library to get the pre-processed version of the original <a href=https://ai.stanford.edu/~amaas/data/sentiment/>IMDB dataset</a>.</p><p>The code below pulls the train and test datasets from <a href=https://github.com/huggingface/datasets>huggingface/datasets</a> using <code>load_dataset('imdb')</code> and transform them into <code>pandas</code> dataframes for use with the <code>simpletransformers</code> library to train the model.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datasets <span style=color:#f92672>import</span> load_dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset_train <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#39;imdb&#39;</span>,split<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;train&#39;</span>)
</span></span><span style=display:flex><span>dataset_train<span style=color:#f92672>.</span>rename_column_(<span style=color:#e6db74>&#39;label&#39;</span>, <span style=color:#e6db74>&#39;labels&#39;</span>)
</span></span><span style=display:flex><span>train_df<span style=color:#f92672>=</span>pd<span style=color:#f92672>.</span>DataFrame(dataset_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset_test <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#39;imdb&#39;</span>,split<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;test&#39;</span>)
</span></span><span style=display:flex><span>dataset_test<span style=color:#f92672>.</span>rename_column_(<span style=color:#e6db74>&#39;label&#39;</span>, <span style=color:#e6db74>&#39;labels&#39;</span>)
</span></span><span style=display:flex><span>test_df<span style=color:#f92672>=</span>pd<span style=color:#f92672>.</span>DataFrame(dataset_test)
</span></span></code></pre></div><p>Once done we can take a look at the <code>head()</code> of the training set to check if our data has been retrieved properly.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train_df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><p>We also double check the dataset properties are exactly the same as those reported in the papers (25,000 train, 25,000 test size, balanced). <strong><code>0</code></strong> is the <strong><code>negative</code></strong> polarity class while <strong><code>1</code></strong> is the <strong><code>positive</code></strong> polarity class.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=color:#f92672>=</span> [[train_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>0</span>], test_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>0</span>]], 
</span></span><span style=display:flex><span>        [train_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>1</span>], test_df<span style=color:#f92672>.</span>labels<span style=color:#f92672>.</span>value_counts()[<span style=color:#ae81ff>1</span>]]]
</span></span><span style=display:flex><span><span style=color:#75715e># Prints out the dataset sizes of train test and validate as per the table.</span>
</span></span><span style=display:flex><span>pd<span style=color:#f92672>.</span>DataFrame(data, columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;Train&#34;</span>, <span style=color:#e6db74>&#34;Test&#34;</span>])
</span></span></code></pre></div><h2 id=training-and-testing-the-model>Training and Testing the Model<a hidden class=anchor aria-hidden=true href=#training-and-testing-the-model>#</a></h2><h4 id=set-the-hyperparmeters>Set the Hyperparmeters<a hidden class=anchor aria-hidden=true href=#set-the-hyperparmeters>#</a></h4><p>First we setup the hyperparamters, using the hyperparemeters specified in the Yang et al. (2019) paper whenever possible (we take Yelp hyperparameters as IMDB ones are not specified). The comparison of hyperparameters is shown in the table below. The major difference is due to GPU memory limitations we are unable to use a sequence length of 512, instead we use a sliding window on a sequence length of 64. We also train to 1 epoch only as want the training to complete fast.</p><table><thead><tr><th>Parameter</th><th>Ours</th><th>Paper</th></tr></thead><tbody><tr><td>Epochs</td><td>1</td><td>?</td></tr><tr><td>Batch Size</td><td>128</td><td>128</td></tr><tr><td>Seq Length</td><td>64</td><td>512</td></tr><tr><td>Learning Rate</td><td>1e-5</td><td>1e-5</td></tr><tr><td>Weight decay</td><td>1e-2</td><td>1e-2</td></tr></tbody></table><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train_args <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;reprocess_input_data&#39;</span>: <span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;overwrite_output_dir&#39;</span>: <span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;sliding_window&#39;</span>: <span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;max_seq_length&#39;</span>: <span style=color:#ae81ff>64</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;num_train_epochs&#39;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;learning_rate&#39;</span>: <span style=color:#ae81ff>0.00001</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;weight_decay&#39;</span>: <span style=color:#ae81ff>0.01</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;train_batch_size&#39;</span>: <span style=color:#ae81ff>128</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;fp16&#39;</span>: <span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;output_dir&#39;</span>: <span style=color:#e6db74>&#39;/outputs/&#39;</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=train-the-model>Train the Model<a hidden class=anchor aria-hidden=true href=#train-the-model>#</a></h4><p>Once we have setup the hyperparemeters in the <code>train_args</code> dictionary, the next step would be to train the model. We use the <a href=https://huggingface.co/xlnet-base-cased><code>xlnet-base-cased</code> model</a> from the awesome <a href=https://github.com/huggingface/transformers>Hugging Face Transformers</a> library and use the <a href=https://simpletransformers.ai/docs/classification-models/>Simple Transformers library</a> on top of it to make it so we can train the classification model with just 2 lines of code.</p><p><a href=https://arxiv.org/pdf/1906.08237.pdf>XLNet</a> is an auto-regressive language model which outputs the joint probability of a sequence of tokens based on the transformer architecture with recurrence. Although its also bigger than BERT and has a (slightly) different architecture, it&rsquo;s change in training objective is probably the biggest contribution. It&rsquo;s training objective is to predict each word in a sequence using any combination of other words in that sequence which seems to perform better on ambiguous contexts.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> simpletransformers.classification <span style=color:#f92672>import</span> ClassificationModel
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> logging
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sklearn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>logging<span style=color:#f92672>.</span>basicConfig(level<span style=color:#f92672>=</span>logging<span style=color:#f92672>.</span>DEBUG)
</span></span><span style=display:flex><span>transformers_logger <span style=color:#f92672>=</span> logging<span style=color:#f92672>.</span>getLogger(<span style=color:#e6db74>&#39;transformers&#39;</span>)
</span></span><span style=display:flex><span>transformers_logger<span style=color:#f92672>.</span>setLevel(logging<span style=color:#f92672>.</span>WARNING)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># We use the XLNet base cased pre-trained model.</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> ClassificationModel(<span style=color:#e6db74>&#39;xlnet&#39;</span>, <span style=color:#e6db74>&#39;xlnet-base-cased&#39;</span>, num_labels<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, args<span style=color:#f92672>=</span>train_args) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the model, there is no development or validation set for this dataset </span>
</span></span><span style=display:flex><span><span style=color:#75715e># https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train_model(train_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Evaluate the model in terms of accuracy score</span>
</span></span><span style=display:flex><span>result, model_outputs, wrong_predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>eval_model(test_df, acc<span style=color:#f92672>=</span>sklearn<span style=color:#f92672>.</span>metrics<span style=color:#f92672>.</span>accuracy_score)
</span></span></code></pre></div><p>We see that the output accuracy from the model after training for 1 epoch is <strong>92.2%</strong> (&lsquo;acc&rsquo;: 0.92156).</p><h2 id=using-the-model-running-inference>Using the Model (Running Inference)<a hidden class=anchor aria-hidden=true href=#using-the-model-running-inference>#</a></h2><p>Running the model to do some predictions/inference is as simple as calling <code>model.predict(input_list)</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>samples <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;The script is nice.Though the casting is absolutely non-watchable.No style. the costumes do not look like some from the High Highbury society. Comparing Gwyneth Paltrow with Kate Beckinsale I can only say that Ms. Beckinsale speaks British English better than Ms. Paltrow, though in Ms. Paltrow</span><span style=color:#ae81ff>\&#39;</span><span style=color:#e6db74>s acting lies the very nature of Emma Woodhouse. Mr. Northam undoubtedly is the best Mr. Knightley of all versions, he is romantic and not at all sharp-looking and unfeeling like Mr. Knightley in the TV-version. P.S.The spectator cannot see at all Mr. Elton-Ms. Smith relationship</span><span style=color:#ae81ff>\&#39;</span><span style=color:#e6db74>s development as it was in the motion version, so one cannot understand where was all Emma</span><span style=color:#ae81ff>\&#39;</span><span style=color:#e6db74>s trying of make a Elton-Smith match (besides of the portrait).&#39;</span>]
</span></span><span style=display:flex><span>predictions, _ <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(samples)
</span></span><span style=display:flex><span>label_dict <span style=color:#f92672>=</span> {<span style=color:#ae81ff>0</span>: <span style=color:#e6db74>&#39;negative&#39;</span>, <span style=color:#ae81ff>1</span>: <span style=color:#e6db74>&#39;positive&#39;</span>}
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> idx, sample <span style=color:#f92672>in</span> enumerate(samples):
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> - </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(idx, label_dict[predictions[idx]], sample))
</span></span></code></pre></div><p>We can connect to Google Drive with the following code to save any files you want to persist. You can also click the <code>Files</code> icon on the left panel and click <code>Mount Drive</code> to mount your Google Drive.</p><p>The root of your Google Drive will be mounted to <code>/content/drive/My Drive/</code>. If you have problems mounting the drive, you can check out this <a href=https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166>tutorial</a>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> google.colab <span style=color:#f92672>import</span> drive
</span></span><span style=display:flex><span>drive<span style=color:#f92672>.</span>mount(<span style=color:#e6db74>&#39;/content/drive/&#39;</span>)
</span></span></code></pre></div><p>You can move the model checkpount files which are saved in the <code>/outputs/</code> directory to your Google Drive.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> shutil
</span></span><span style=display:flex><span>shutil<span style=color:#f92672>.</span>move(<span style=color:#e6db74>&#39;/outputs/&#39;</span>, <span style=color:#e6db74>&#34;/content/drive/My Drive/outputs/&#34;</span>)
</span></span></code></pre></div><h2 id=more-such-notebooks>More Such Notebooks<a hidden class=anchor aria-hidden=true href=#more-such-notebooks>#</a></h2><p>Visit or star the <a href=https://github.com/eugenesiow/practical-ml>eugenesiow/practical-ml</a> repository on Github for more such notebooks:</p><iframe src="https://ghbtns.com/github-btn.html?user=eugenesiow&repo=practical-ml&type=star&count=true&size=large" frameborder=0 scrolling=0 width=170 height=30 title="Practical Machine Learning"></iframe><h2 id=alternatives-to-colab>Alternatives to Colab<a hidden class=anchor aria-hidden=true href=#alternatives-to-colab>#</a></h2><p>Here are some alternatives to Google Colab to train models or run Jupyter Notebooks in the cloud:</p><ul><li><a href=https://news.machinelearning.sg/posts/google_colab_vs_paperspace_gradient/>Google Colab vs Paperspace Gradient</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://news.machinelearning.sg/tags/natural-language-processing/>Natural Language Processing</a></li><li><a href=https://news.machinelearning.sg/tags/deep-learning/>Deep Learning</a></li><li><a href=https://news.machinelearning.sg/tags/machine-learning/>Machine Learning</a></li><li><a href=https://news.machinelearning.sg/tags/gpu/>GPU</a></li><li><a href=https://news.machinelearning.sg/tags/source-code/>Source Code</a></li><li><a href=https://news.machinelearning.sg/tags/pytorch/>PyTorch</a></li><li><a href=https://news.machinelearning.sg/tags/sentiment-analysis/>Sentiment Analysis</a></li><li><a href=https://news.machinelearning.sg/tags/jupyter-notebook/>Jupyter Notebook</a></li><li><a href=https://news.machinelearning.sg/tags/colab/>Colab</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on twitter" href="https://twitter.com/intent/tweet/?text=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f&hashtags=NaturalLanguageProcessing%2cDeepLearning%2cMachineLearning%2cGPU%2cSourceCode%2cPyTorch%2cSentimentAnalysis%2cJupyterNotebook%2cColab"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f&title=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet&summary=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet&source=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f&title=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on whatsapp" href="https://api.whatsapp.com/send?text=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet%20-%20https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Sentiment Analysis on Movie Reviews with XLNet on telegram" href="https://telegram.me/share/url?text=Sentiment%20Analysis%20on%20Movie%20Reviews%20with%20XLNet&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fsentiment_analysis_on_movie_reviews_with_xlnet%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://news.machinelearning.sg/>News @ machinelearning.sg</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>