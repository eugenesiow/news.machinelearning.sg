<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year | News @ machinelearning.sg</title><meta name=keywords content="NeurIPS,Deep Learning,Singapore,Machine Learning,Neuroscience,Conferences"><meta name=description content="tl;dr NeurIPS is the largest and argubably the most prestigious machine learning research conference internationally. We look at the 44 accepted publications from singapore-based authors in this 2020 edition of the conference, which is happening live this week (6 - 12 Dec 2020).
 What is NeurIPS? NeurIPS is the Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS). It is the largest conference in Artificial Intelligence with a specific focus on machine learning and neuroscience."><meta name=author content="Eugene"><link rel=canonical href=https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/><link href=https://news.machinelearning.sg/assets/css/stylesheet.min.189e57850a48ac6604e81dc2b824a6325aae66266cb0b21b6883ce5c085e8656.css integrity="sha256-GJ5XhQpIrGYE6B3CuCSmMlquZiZssLIbaIPOXAhehlY=" rel="preload stylesheet" as=style><link rel=icon href=https://news.machinelearning.sg/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://news.machinelearning.sg/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://news.machinelearning.sg/favicon-32x32.png><link rel=apple-touch-icon href=https://news.machinelearning.sg/apple-touch-icon.png><link rel=mask-icon href=https://news.machinelearning.sg/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.79.0"><meta property="og:title" content="NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year"><meta property="og:description" content="tl;dr NeurIPS is the largest and argubably the most prestigious machine learning research conference internationally. We look at the 44 accepted publications from singapore-based authors in this 2020 edition of the conference, which is happening live this week (6 - 12 Dec 2020).
 What is NeurIPS? NeurIPS is the Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS). It is the largest conference in Artificial Intelligence with a specific focus on machine learning and neuroscience."><meta property="og:type" content="article"><meta property="og:url" content="https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/"><meta property="og:image" content="https://news.machinelearning.sg/neurips2020_logo.png"><meta property="article:published_time" content="2020-12-08T09:00:00+08:00"><meta property="article:modified_time" content="2020-12-08T09:00:00+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://news.machinelearning.sg/neurips2020_logo.png"><meta name=twitter:title content="NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year"><meta name=twitter:description content="tl;dr NeurIPS is the largest and argubably the most prestigious machine learning research conference internationally. We look at the 44 accepted publications from singapore-based authors in this 2020 edition of the conference, which is happening live this week (6 - 12 Dec 2020).
 What is NeurIPS? NeurIPS is the Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS). It is the largest conference in Artificial Intelligence with a specific focus on machine learning and neuroscience."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year","name":"NeurIPS2020 - Singapore\u0027s Entries at the Top Machine Learning Conference This Year","description":"tl;dr NeurIPS is the largest and argubably the most prestigious machine learning research conference internationally. We look at the 44 accepted publications from singapore-based …","keywords":["NeurIPS","Deep Learning","Singapore","Machine Learning","Neuroscience","Conferences"],"articleBody":" tl;dr NeurIPS is the largest and argubably the most prestigious machine learning research conference internationally. We look at the 44 accepted publications from singapore-based authors in this 2020 edition of the conference, which is happening live this week (6 - 12 Dec 2020).\n What is NeurIPS? NeurIPS is the Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS). It is the largest conference in Artificial Intelligence with a specific focus on machine learning and neuroscience. Fueled by the resurgence of neural networks and advent of deep learning in 2012, it has grown to become one of (if not the most) prestigious international ML conference.\nWhat was the acceptance rate like? In the 2020 edition, the conference received 9,467 papers and accepted 1,900 papers, with about 20% acceptance rate across the topics.\n  Figure 1. Acceptance rate in each subject area, with comparison across 2018, 2019 and 2020. Figure retrieved from the official blog post on 8 December 2020.   The three most popular areas, in terms of submissions are: “Algorithms”, “Deep Learning” and “Applications”, although the latter two have seen a decline in the number of submissions. Acceptance rates for “Theory” and “Neuroscience” continue to be much higher than “Data, Challenges, Implementations, and Software”, which highlight the theoretical focus of the conference and the very high bar for application papers.\nWhich SG institute has put out more papers? In the absence of a better metric to measure quality or impact, we look at the volume of accepted submissions per institute from the 44 accepted publications that we have identified as having an SG-based author.\n  Figure 2. Total accepted papers from each SG-based institute and collaborating institutes on these papers.   NUS and NTU top the charts in terms of volume of publications at NeurIPS this year with SUTD and SMU following closely.\nList of Singapore’s Entries We count 44 accepted publications with an author with a SG-based affiliation and they are listed as follows:\n   # paper authors fields     1 Part-dependent Label Noise: Towards Instance-dependent Label Noise Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, Masashi Sugiyama Pattern Recognition, Computer Science, Artificial Intelligence   2 Causal Intervention for Weakly-Supervised Semantic Segmentation. Dong Zhang, Hanwang Zhang, Jinhui Tang, Xian-Sheng Hua, Qianru Sun Segmentation, Natural Language Processing, Computer Science, Artificial Intelligence   3 Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect Kaihua Tang, Jianqiang Huang, Hanwang Zhang Momentum, Econometrics, Mathematics, Form Of The Good, Causal Effect   4 Interventional Few-Shot Learning Zhongqi Yue, Hanwang Zhang, Qianru Sun, Xian-Sheng Hua Medical Physics, Computer Science   5 Provably Consistent Partial-Label Learning Lei Feng, Jiaqi Lv, Bo Han, Miao Xu, Gang Niu, Xin Geng, Bo An, Masashi Sugiyama Theoretical Computer Science, Computer Science   6 Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, Masashi Sugiyama Stochastic Matrix, Algorithm, Mathematics   7 Watch out! Motion is Blurring the Vision of Your Deep Neural Networks Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang, Bing Yu, Wei Feng, Yang Liu Computer Vision, Computer Science, Artificial Intelligence, Deep Neural Networks   8 Federated Bayesian Optimization via Thompson Sampling Zhongxiang Dai, Bryan Kian Hsiang Low, Patrick Jaillet Bayesian Optimization, Thompson Sampling, Machine Learning, Computer Science, Artificial Intelligence   9 Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Page-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David Vázquez, Laurent Charlin Knowledge Management, Computer Science, Continual Learning   10 Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, Xu Chi Job Shop Scheduling, Reinforcement Learning, Operations Research, Computer Science   11 The route to chaos in routing games: When is price of anarchy too optimistic? Thiparat Chotibut, Fryderyk Falniowski, Michał Misiurewicz, Georgios Piliouras Price Of Anarchy, Mathematical Economics, Economics   12 Neural Sparse Voxel Fields Lingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, Christian Theobalt Voxel, Pattern Recognition, Computer Science, Artificial Intelligence   13 Synthesizing Tasks for Block-based Programming Umair Z. Ahmed, Maria Christakis, Aleksandr Efremov, Nigel Fernandez, Ahana Ghosh, Abhik Roychoudhury, Adish Singla Programming Language, Computer Science   14 Variational Bayesian Unlearning Quoc Phong Nguyen, Bryan Kian Hsiang Low, Patrick Jaillet Bayesian Probability, Artificial Intelligence   15 Theory-Inspired Path-Regularized Differential Network Architecture Search Pan Zhou, Caiming Xiong, Richard Socher, Steven Chu Hong Hoi Network Architecture, Artificial Intelligence, Computer Science   16 Rethinking Importance Weighting for Deep Learning under Distribution Shift Tongtong Fang, Nan Lu, Gang Niu, Masashi Sugiyama Weighting, Deep Learning, Machine Learning, Computer Science, Artificial Intelligence   17 ConvBERT: Improving BERT with Span-based Dynamic Convolution Zi-Hang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan Convolution, Algorithm, Computer Science   18 Neural encoding with visual attention Meenakshi Khosla, Gia H. Ngo, Keith Jamison, Amy Kuceyeski, Mert R. Sabuncu Encoding, Speech Recognition, Computer Science, Visual Attention   19 Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi Zhang Reinforcement Learning, Artificial Intelligence, Computer Science   20 MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler. Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, Yi Chang Mesa, Data Mining, Computer Science   21 Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev Xiao Wang, Qi Lei, Ioannis Panageas Langevin Dynamics, Sobolev Space, Geodesic, Manifold, Convergence, Mathematical Analysis, Mathematics   22 Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent Dimitris Fotakis, Thanasis Lianeas, Georgios Piliouras, Stratis Skoulakis Gradient Descent, Dimensionality Reduction, Mathematical Optimization, Computer Science, Online Learning   23 On Testing of Samplers Kuldeep S Meel, Yash Pralhad Pote, Sourav Chakraborty    24 Towards Maximizing the Representation Gap between In-Domain \u0026 Out-of-Distribution Examples Jay Nandy, Wynne Hsu, Mong Li Lee Mathematical Optimization, Computer Science   25 No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix Emmanouil-Vasileios Vlatakis-Gkaragkounis, Lampros Flokas, Thanasis Lianeas, Panayotis Mertikopoulos, Georgios Piliouras Regret, Nash Equilibrium, Mathematical Economics, Economics   26 Optimal Query Complexity of Secure Stochastic Convex Optimization Wei Tang, Chien-Ju Ho, Yang Liu Convex Optimization, Mathematical Optimization, Computer Science   27 Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization Haoliang Li, Yufei Wang, Renjie Wan, Shiqi Wang, Tie-Qiang Li, Alex C. Kot Medical Imaging, Regularization, Pattern Recognition, Computer Science, Artificial Intelligence, Linear Dependency   28 Cross-Scale Internal Graph Neural Network for Image Super-Resolution Shangchen Zhou, Jiawei Zhang, Wangmeng Zuo, Chen Change Loy Algorithm, Computer Science, Cross Scale, Graph Neural Networks, Superresolution   29 Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation Jianyuan Wang, Yiran Zhong, Yuchao Dai, Kaihao Zhang, Pan Ji, Hongdong Li Invariant, Algorithm, Computer Science, Optical Flow Estimation   30 Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation Jianfeng Zhang, Xuecheng Nie, Jiashi Feng Inference, Pose, Machine Learning, Computer Science, Artificial Intelligence   31 Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S Meel, N. V. Vinodchandran Mathematical Analysis, Mathematics, Distance Approximation, High Dimensional   32 The Generalized Lasso with Nonlinear Observations and Generative Priors Zhaoqiang Liu, Jonathan Scarlett Lasso, Prior Probability, Nonlinear System, Generative Grammar, Algorithm, Computer Science   33 Improving Generalization in Reinforcement Learning with Mixture Regularization Kaixin Wang, Bingyi Kang, Jie Shao, Jiashi Feng Reinforcement Learning, Regularization, Artificial Intelligence, Computer Science   34 Correlation Robust Influence Maximization Louis Chen, Divya Padmanabhan, Chee Chin Lim, Karthik Natarajan Maximization, Correlation, Mathematical Optimization, Mathematics   35 Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization Sreejith Balakrishnan, Quoc Phong Nguyen, Bryan Kian Hsiang Low, Harold Soh Bayesian Optimization, Artificial Intelligence, Computer Science, Inverse Reinforcement Learning   36 Taming Discrete Integration via the Boon of Dimensionality Jeffrey M. Dudek, Dror Fried, Kuldeep S. Meel Curse Of Dimensionality, Theoretical Computer Science, Computer Science   37 Digraph Inception Convolutional Networks Zekun Tong, Yuxuan Liang, Changsheng Sun, Xinke Li, David Rosenblum, Andrew Lim Digraph, Discrete Mathematics, Computer Science   38 Towards Theoretically Understanding Why Sgd Generalizes Better Than Adam in Deep Learning Pan Zhou, Jiashi Feng, Chao Ma, Caiming Xiong, Steven Chu Hong Hoi, Weinan E Deep Learning, Cognitive Science, Computer Science, Artificial Intelligence   39 Balanced Meta-Softmax for Long-Tailed Visual Recognition Ren Jiawei, Cunjun Yu, shunan sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, hongsheng Li Softmax Function, Speech Recognition, Computer Science, Visual Recognition   40 Chaos, Extremism and Optimism: Volume Analysis of Learning in Games Yun Kuen Cheung, Georgios Piliouras Optimism, Social Psychology, Psychology, Volume Analysis   41 Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang Time Series, Multivariate Statistics, Pattern Recognition, Computer Science, Artificial Intelligence, Graph Neural Networks   42 Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning Jianda Chen, Shangyu Chen, Sinno Jialin Pan Reinforcement Learning, Channel, Pruning, Distributed Computing, Computer Science   43 Self-Supervised Relationship Probing Jiuxiang Gu, Jason Kuen, Shafiq Joty, Jianfei Cai, Vlad Morariu, Handong Zhao, Tong Sun Machine Learning, Psychology, Artificial Intelligence   44 Partially View-aligned Clustering Zhenyu Huang, Peng Hu, Joey Tianyi Zhou, Jiancheng Lv, Xi Peng Cluster Analysis, Pattern Recognition, Computer Science, Artificial Intelligence    There is no particular order of note. The list was ranked by early citations, which is as good as random for now. Data was obtained from the pretty awesome Microsoft Academic Graph.\n","wordCount":"1541","inLanguage":"en","image":"https://news.machinelearning.sg/neurips2020_logo.png","datePublished":"2020-12-08T09:00:00+08:00","dateModified":"2020-12-08T09:00:00+08:00","author":{"@type":"Person","name":"Eugene"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/"},"publisher":{"@type":"Organization","name":"News @ machinelearning.sg","logo":{"@type":"ImageObject","url":"https://news.machinelearning.sg/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://news.machinelearning.sg/ accesskey=h>News</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span><span class=lang-switch><ul><li><a href=https://machinelearning.sg>machinelearning.sg</a></li></ul></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://news.machinelearning.sg/about/><span>About</span></a></li><li><a href=https://news.machinelearning.sg/archives/><span>Archive</span></a></li><li><a href=https://news.machinelearning.sg/tags/><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year</h1><div class=post-meta>December 8, 2020&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Eugene</div></header><figure class=entry-cover><img srcset="https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo_hu583016389a0d72aa87d5b650743975ce_76374_360x0_resize_box_2.png 360w ,https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo_hu583016389a0d72aa87d5b650743975ce_76374_480x0_resize_box_2.png 480w ,https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo_hu583016389a0d72aa87d5b650743975ce_76374_720x0_resize_box_2.png 720w ,https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo_hu583016389a0d72aa87d5b650743975ce_76374_1080x0_resize_box_2.png 1080w ,https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo_hu583016389a0d72aa87d5b650743975ce_76374_1500x0_resize_box_2.png 1500w ,https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo.png 1853w" sizes="(min-width: 768px) 720px, 100vw" src=https://news.machinelearning.sg/posts/neurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year/neurips2020_logo.png alt="The Conference and Workshop on Neural Information Processing Systems (NeurIPS) 2020."><p>The Conference and Workshop on Neural Information Processing Systems (NeurIPS) 2020.</p></figure><div class=toc><details><summary><div class=details accesskey=c>Table of Contents</div></summary><blockquote><ul><li><a href=#what-is-neurips aria-label="What is NeurIPS?">What is NeurIPS?</a></li><li><a href=#what-was-the-acceptance-rate-like aria-label="What was the acceptance rate like?">What was the acceptance rate like?</a><ul><ul><li><a href=# aria-label="Figure 1. Acceptance rate in each subject area, with comparison across 2018, 2019 and 2020. Figure retrieved from the official blog post on 8 December 2020.">Figure 1. Acceptance rate in each subject area, with comparison across 2018, 2019 and 2020. Figure retrieved from the official blog post on 8 December 2020.</a></li></ul></ul></li><li><a href=#which-sg-institute-has-put-out-more-papers aria-label="Which SG institute has put out more papers?">Which SG institute has put out more papers?</a><ul><ul><li><a href=# aria-label="Figure 2. Total accepted papers from each SG-based institute and collaborating institutes on these papers.">Figure 2. Total accepted papers from each SG-based institute and collaborating institutes on these papers.</a></li></ul></ul></li><li><a href=#list-of-singapores-entries aria-label="List of Singapore&amp;rsquo;s Entries">List of Singapore&rsquo;s Entries</a></li></ul></blockquote></details></div><div class=post-content><blockquote><p><strong>tl;dr</strong> <em>NeurIPS</em> is the largest and argubably the most prestigious machine learning research conference internationally.
We look at the 44 accepted publications from singapore-based authors in this 2020 edition of the conference,
which is happening live this week (6 - 12 Dec 2020).</p></blockquote><h2 id=what-is-neurips>What is NeurIPS?<a hidden class=anchor aria-hidden=true href=#what-is-neurips>#</a></h2><p>NeurIPS is the Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS).
It is the <a href=https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems#Topics>largest conference</a>
in Artificial Intelligence with a specific focus on machine learning and neuroscience. Fueled by the resurgence of neural
networks and advent of deep learning in 2012, it has grown to become one of (if not the most) prestigious international
ML conference.</p><h2 id=what-was-the-acceptance-rate-like>What was the acceptance rate like?<a hidden class=anchor aria-hidden=true href=#what-was-the-acceptance-rate-like>#</a></h2><p>In the 2020 edition, the conference
received <a href=https://neuripsconf.medium.com/what-we-learned-from-neurips-2020-reviewing-process-e24549eea38f>9,467 papers</a>
and accepted 1,900 papers, with about 20% acceptance rate across the topics.</p><figure><img src=neurips2020_acceptance.png><figcaption><h4>Figure 1. Acceptance rate in each subject area, with comparison across 2018, 2019 and 2020. Figure retrieved from the official blog post on 8 December 2020.</h4></figcaption></figure><p>The three most popular areas, in terms of submissions are: &ldquo;Algorithms&rdquo;, &ldquo;Deep Learning&rdquo; and &ldquo;Applications&rdquo;,
although the latter two have seen a decline in the number of submissions. Acceptance rates for &ldquo;Theory&rdquo; and &ldquo;Neuroscience&rdquo;
continue to be much higher than &ldquo;Data, Challenges, Implementations, and Software&rdquo;, which highlight the theoretical focus
of the conference and the very high bar for application papers.</p><h2 id=which-sg-institute-has-put-out-more-papers>Which SG institute has put out more papers?<a hidden class=anchor aria-hidden=true href=#which-sg-institute-has-put-out-more-papers>#</a></h2><p>In the absence of a better metric to measure quality or impact, we look at the volume of accepted submissions per institute from the
44 accepted publications that we have identified as having an SG-based author.</p><figure><img src=neurips2020_sg_institutes.png><figcaption><h4>Figure 2. Total accepted papers from each SG-based institute and collaborating institutes on these papers.</h4></figcaption></figure><p>NUS and NTU top the charts in terms of volume of publications at NeurIPS this year with SUTD and SMU following closely.</p><h2 id=list-of-singapores-entries>List of Singapore&rsquo;s Entries<a hidden class=anchor aria-hidden=true href=#list-of-singapores-entries>#</a></h2><p>We count 44 accepted publications with an author with a SG-based affiliation and they are listed as follows:</p><table><thead><tr><th style=text-align:right>#</th><th>paper</th><th>authors</th><th>fields</th></tr></thead><tbody><tr><td style=text-align:right>1</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/5607fe8879e4fd269e88387e8cb30b7e-Abstract.html>Part-dependent Label Noise: Towards Instance-dependent Label Noise</a></td><td><a href=https://academic.microsoft.com/author/2947512387>Xiaobo Xia</a>, <a href=https://academic.microsoft.com/author/2137595165 title="University Of Sydney">Tongliang Liu</a>, <a href=https://academic.microsoft.com/author/2530323620 title="Hong Kong Baptist University">Bo Han</a>, <a href=https://academic.microsoft.com/author/2947149074>Nannan Wang</a>, <a href=https://academic.microsoft.com/author/2129560754 title="University Of Melbourne">Mingming Gong</a>, <a href=https://academic.microsoft.com/author/3005928827>Haifeng Liu</a>, <a href=https://academic.microsoft.com/author/2032345308 title="Nanyang Technological University">Gang Niu</a>, <a href=https://academic.microsoft.com/author/2104129307 title="University Of Sydney">Dacheng Tao</a>, <a href=https://academic.microsoft.com/author/2130456104 title="University Of Tokyo">Masashi Sugiyama</a></td><td>Pattern Recognition, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>2</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/07211688a0869d995947a8fb11b215d6-Abstract.html>Causal Intervention for Weakly-Supervised Semantic Segmentation.</a></td><td><a href=https://academic.microsoft.com/author/3043810921>Dong Zhang</a>, <a href=https://academic.microsoft.com/author/2141833608 title="Nanyang Technological University">Hanwang Zhang</a>, <a href=https://academic.microsoft.com/author/2150813751 title="Nanjing University Of Science And Technology">Jinhui Tang</a>, <a href=https://academic.microsoft.com/author/2165599877 title=Microsoft>Xian-Sheng Hua</a>, <a href=https://academic.microsoft.com/author/2115739112 title="Singapore Management University">Qianru Sun</a></td><td>Segmentation, Natural Language Processing, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>3</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/1091660f3dff84fd648efe31391c5524-Abstract.html>Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect</a></td><td><a href=https://academic.microsoft.com/author/3007552043 title="Nanyang Technological University">Kaihua Tang</a>, <a href=https://academic.microsoft.com/author/2990644215 title="Nanyang Technological University">Jianqiang Huang</a>, <a href=https://academic.microsoft.com/author/2141833608 title="Nanyang Technological University">Hanwang Zhang</a></td><td>Momentum, Econometrics, Mathematics, Form Of The Good, Causal Effect</td></tr><tr><td style=text-align:right>4</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/1cc8a8ea51cd0adddf5dab504a285915-Abstract.html>Interventional Few-Shot Learning</a></td><td><a href=https://academic.microsoft.com/author/3088862368 title="Nanyang Technological University">Zhongqi Yue</a>, <a href=https://academic.microsoft.com/author/2141833608 title="Nanyang Technological University">Hanwang Zhang</a>, <a href=https://academic.microsoft.com/author/2115739112 title="Singapore Management University">Qianru Sun</a>, <a href=https://academic.microsoft.com/author/3088884090 title="Alibaba Group">Xian-Sheng Hua</a></td><td>Medical Physics, Computer Science</td></tr><tr><td style=text-align:right>5</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/7bd28f15a49d5e5848d6ec70e584e625-Abstract.html>Provably Consistent Partial-Label Learning</a></td><td><a href=https://academic.microsoft.com/author/2903921810 title="Nanyang Technological University">Lei Feng</a>, <a href=https://academic.microsoft.com/author/2564312221 title="Southeast University">Jiaqi Lv</a>, <a href=https://academic.microsoft.com/author/2530323620 title="Hong Kong Baptist University">Bo Han</a>, <a href=https://academic.microsoft.com/author/2787583120 title="University Of Queensland">Miao Xu</a>, <a href=https://academic.microsoft.com/author/2032345308 title="Nanyang Technological University">Gang Niu</a>, <a href=https://academic.microsoft.com/author/2124809355 title="Southeast University">Xin Geng</a>, <a href=https://academic.microsoft.com/author/2169236860 title="Nanyang Technological University">Bo An</a>, <a href=https://academic.microsoft.com/author/2130456104 title="University Of Tokyo">Masashi Sugiyama</a></td><td>Theoretical Computer Science, Computer Science</td></tr><tr><td style=text-align:right>6</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning</a></td><td><a href=https://academic.microsoft.com/author/3004420354>Yu Yao</a>, <a href=https://academic.microsoft.com/author/2137595165 title="University Of Sydney">Tongliang Liu</a>, <a href=https://academic.microsoft.com/author/2530323620 title="Hong Kong Baptist University">Bo Han</a>, <a href=https://academic.microsoft.com/author/3035005292>Mingming Gong</a>, <a href=https://academic.microsoft.com/author/3034283391>Jiankang Deng</a>, <a href=https://academic.microsoft.com/author/2032345308 title="Nanyang Technological University">Gang Niu</a>, <a href=https://academic.microsoft.com/author/2130456104 title="University Of Tokyo">Masashi Sugiyama</a></td><td>Stochastic Matrix, Algorithm, Mathematics</td></tr><tr><td style=text-align:right>7</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/0a73de68f10e15626eb98701ecf03adb-Abstract.html>Watch out! Motion is Blurring the Vision of Your Deep Neural Networks</a></td><td><a href=https://academic.microsoft.com/author/2509746746 title="Tianjin University">Qing Guo</a>, <a href=https://academic.microsoft.com/author/44738307 title="Alibaba Group">Felix Juefei-Xu</a>, <a href=https://academic.microsoft.com/author/2119556171 title="Nanyang Technological University">Xiaofei Xie</a>, <a href=https://academic.microsoft.com/author/2190231381 title="Kyushu University">Lei Ma</a>, <a href=https://academic.microsoft.com/author/2973063392 title="Nanyang Technological University">Jian Wang</a>, <a href=https://academic.microsoft.com/author/3088576736 title="Kyushu University">Bing Yu</a>, <a href=https://academic.microsoft.com/author/2639293518 title="Tianjin University">Wei Feng</a>, <a href=https://academic.microsoft.com/author/2201441985 title="Beihang University">Yang Liu</a></td><td>Computer Vision, Computer Science, Artificial Intelligence, Deep Neural Networks</td></tr><tr><td style=text-align:right>8</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/6dfe08eda761bd321f8a9b239f6f4ec3-Abstract.html>Federated Bayesian Optimization via Thompson Sampling</a></td><td><a href=https://academic.microsoft.com/author/2500337024 title="National University Of Singapore">Zhongxiang Dai</a>, <a href=https://academic.microsoft.com/author/2133261218 title="National University Of Singapore">Bryan Kian Hsiang Low</a>, <a href=https://academic.microsoft.com/author/1812487863 title="Massachusetts Institute Of Technology">Patrick Jaillet</a></td><td>Bayesian Optimization, Thompson Sampling, Machine Learning, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>9</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/c0a271bc0ecb776a094786474322cb82-Abstract.html>Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning</a></td><td><a href=https://academic.microsoft.com/author/2899912930 title="Hec Montreal">Massimo Caccia</a>, <a href=https://academic.microsoft.com/author/2607349451 title="Autonomous University Of Barcelona">Pau Rodriguez</a>, <a href=https://academic.microsoft.com/author/3011134698>Oleksiy Ostapenko</a>, <a href=https://academic.microsoft.com/author/3011271048>Fabrice Normandin</a>, <a href=https://academic.microsoft.com/author/2598034946 title="National University Of Singapore">Min Lin</a>, <a href=https://academic.microsoft.com/author/2970122539>Lucas Page-Caccia</a>, <a href=https://academic.microsoft.com/author/3100192822>Issam Hadj Laradji</a>, <a href=https://academic.microsoft.com/author/1653753694 title=Ibm>Irina Rish</a>, <a href=https://academic.microsoft.com/author/2096633958 title=Google>Alexandre Lacoste</a>, <a href=https://academic.microsoft.com/author/2127378106 title="Autonomous University Of Barcelona">David Vázquez</a>, <a href=https://academic.microsoft.com/author/242798638 title="Hec Montreal">Laurent Charlin</a></td><td>Knowledge Management, Computer Science, Continual Learning</td></tr><tr><td style=text-align:right>10</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/11958dfee29b6709f48a9ba0387a2431-Abstract.html>Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning</a></td><td><a href=https://academic.microsoft.com/author/3094336912>Cong Zhang</a>, <a href=https://academic.microsoft.com/author/3094294241>Wen Song</a>, <a href=https://academic.microsoft.com/author/3094010673>Zhiguang Cao</a>, <a href=https://academic.microsoft.com/author/2422123818 title="Nanyang Technological University">Jie Zhang</a>, <a href=https://academic.microsoft.com/author/3094065571>Puay Siew Tan</a>, <a href=https://academic.microsoft.com/author/3104748043>Xu Chi</a></td><td>Job Shop Scheduling, Reinforcement Learning, Operations Research, Computer Science</td></tr><tr><td style=text-align:right>11</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/0887f1a5b9970ad13f46b8c1485f7900-Abstract.html>The route to chaos in routing games: When is price of anarchy too optimistic?</a></td><td><a href=https://academic.microsoft.com/author/2260059114 title="Harvard University">Thiparat Chotibut</a>, <a href=https://academic.microsoft.com/author/130184226>Fryderyk Falniowski</a>, <a href=https://academic.microsoft.com/author/1721670277 title="Indiana University Purdue University Indianapolis">Michał Misiurewicz</a>, <a href=https://academic.microsoft.com/author/2585738440 title="Singapore University Of Technology And Design">Georgios Piliouras</a></td><td>Price Of Anarchy, Mathematical Economics, Economics</td></tr><tr><td style=text-align:right>12</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/b4b758962f17808746e9bb832a6fa4b8-Abstract.html>Neural Sparse Voxel Fields</a></td><td><a href=https://academic.microsoft.com/author/2737123536 title="Max Planck Society">Lingjie Liu</a>, <a href=https://academic.microsoft.com/author/3044249667 title="Max Planck Society">Jiatao Gu</a>, <a href=https://academic.microsoft.com/author/2906458072 title=Facebook>Kyaw Zaw Lin</a>, <a href=https://academic.microsoft.com/author/2160663097 title="National University Of Singapore">Tat-Seng Chua</a>, <a href=https://academic.microsoft.com/author/214804705 title="National University Of Singapore">Christian Theobalt</a></td><td>Voxel, Pattern Recognition, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>13</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/fd9dd764a6f1d73f4340d570804eacc4-Abstract.html>Synthesizing Tasks for Block-based Programming</a></td><td><a href=https://academic.microsoft.com/author/1982167284 title="Indian Institute Of Technology Kanpur">Umair Z. Ahmed</a>, <a href=https://academic.microsoft.com/author/3040159607>Maria Christakis</a>, <a href=https://academic.microsoft.com/author/3038804907>Aleksandr Efremov</a>, <a href=https://academic.microsoft.com/author/3039215482>Nigel Fernandez</a>, <a href=https://academic.microsoft.com/author/2947326300 title="Max Planck Society">Ahana Ghosh</a>, <a href=https://academic.microsoft.com/author/2153766775 title="National University Of Singapore">Abhik Roychoudhury</a>, <a href=https://academic.microsoft.com/author/3085820695 title="Max Planck Society">Adish Singla</a></td><td>Programming Language, Computer Science</td></tr><tr><td style=text-align:right>14</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/b8a6550662b363eb34145965d64d0cfb-Abstract.html>Variational Bayesian Unlearning</a></td><td><a href=https://academic.microsoft.com/author/2540213700 title="National University Of Singapore">Quoc Phong Nguyen</a>, <a href=https://academic.microsoft.com/author/2133261218 title="National University Of Singapore">Bryan Kian Hsiang Low</a>, <a href=https://academic.microsoft.com/author/1812487863 title="Massachusetts Institute Of Technology">Patrick Jaillet</a></td><td>Bayesian Probability, Artificial Intelligence</td></tr><tr><td style=text-align:right>15</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/5e1b18c4c6a6d31695acbae3fd70ecc6-Abstract.html>Theory-Inspired Path-Regularized Differential Network Architecture Search</a></td><td><a href=https://academic.microsoft.com/author/2890817041 title="National University Of Singapore">Pan Zhou</a>, <a href=https://academic.microsoft.com/author/2095665791 title="Salesforce Com">Caiming Xiong</a>, <a href=https://academic.microsoft.com/author/1964982643 title="Salesforce Com">Richard Socher</a>, <a href=https://academic.microsoft.com/author/108406206 title="Singapore Management University">Steven Chu Hong Hoi</a></td><td>Network Architecture, Artificial Intelligence, Computer Science</td></tr><tr><td style=text-align:right>16</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/8b9e7ab295e87570551db122a04c6f7c-Abstract.html>Rethinking Importance Weighting for Deep Learning under Distribution Shift</a></td><td><a href=https://academic.microsoft.com/author/3034051835>Tongtong Fang</a>, <a href=https://academic.microsoft.com/author/2889186858 title="University Of Tokyo">Nan Lu</a>, <a href=https://academic.microsoft.com/author/2032345308 title="Nanyang Technological University">Gang Niu</a>, <a href=https://academic.microsoft.com/author/2130456104 title="University Of Tokyo">Masashi Sugiyama</a></td><td>Weighting, Deep Learning, Machine Learning, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>17</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/96da2f590cd7246bbde0051047b0d6f7-Abstract.html>ConvBERT: Improving BERT with Span-based Dynamic Convolution</a></td><td><a href=https://academic.microsoft.com/author/2995815406 title="University Of Science And Technology Of China">Zi-Hang Jiang</a>, <a href=https://academic.microsoft.com/author/2224491906 title="Sun Yat Sen University">Weihao Yu</a>, <a href=https://academic.microsoft.com/author/3059815736>Daquan Zhou</a>, <a href=https://academic.microsoft.com/author/2528730867 title="National University Of Singapore">Yunpeng Chen</a>, <a href=https://academic.microsoft.com/author/3081085593 title="National University Of Singapore">Jiashi Feng</a>, <a href=https://academic.microsoft.com/author/2144833106 title="University Of Science And Technology Of China">Shuicheng Yan</a></td><td>Convolution, Algorithm, Computer Science</td></tr><tr><td style=text-align:right>18</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/b71f5aaf3371c2cdfb7a7c0497f569d4-Abstract.html>Neural encoding with visual attention</a></td><td><a href=https://academic.microsoft.com/author/2562196444 title="Cornell University">Meenakshi Khosla</a>, <a href=https://academic.microsoft.com/author/2886398484 title="Agency For Science Technology And Research">Gia H. Ngo</a>, <a href=https://academic.microsoft.com/author/2799225839 title="Cornell University">Keith Jamison</a>, <a href=https://academic.microsoft.com/author/1991100140 title="Cornell University">Amy Kuceyeski</a>, <a href=https://academic.microsoft.com/author/2809712987 title="Cornell University">Mert R. Sabuncu</a></td><td>Encoding, Speech Recognition, Computer Science, Visual Attention</td></tr><tr><td style=text-align:right>19</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/bf65417dcecc7f2b0006e1f5793b7143-Abstract.html>Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games</a></td><td><a href=https://academic.microsoft.com/author/3093639124 title="University Of Technology Sydney">Yunqiu Xu</a>, <a href=https://academic.microsoft.com/author/2152013896 title=Tencent>Meng Fang</a>, <a href=https://academic.microsoft.com/author/2420538054 title="University Of Technology Sydney">Ling Chen</a>, <a href=https://academic.microsoft.com/author/3093555977 title="University College London">Yali Du</a>, <a href=https://academic.microsoft.com/author/2170372657 title="Institute Of High Performance Computing Singapore">Joey Tianyi Zhou</a>, <a href=https://academic.microsoft.com/author/2166080598 title="University Of Technology Sydney">Chengqi Zhang</a></td><td>Reinforcement Learning, Artificial Intelligence, Computer Science</td></tr><tr><td style=text-align:right>20</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/a64bd53139f71961c5c31a9af03d775e-Abstract.html>MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler.</a></td><td><a href=https://academic.microsoft.com/author/2972132139 title="Jilin University">Zhining Liu</a>, <a href=https://academic.microsoft.com/author/3093180775 title="National University Of Singapore">Pengfei Wei</a>, <a href=https://academic.microsoft.com/author/2678264890 title="University Of Technology Sydney">Jing Jiang</a>, <a href=https://academic.microsoft.com/author/2683752314 title=Microsoft>Wei Cao</a>, <a href=https://academic.microsoft.com/author/2609123459 title=Microsoft>Jiang Bian</a>, <a href=https://academic.microsoft.com/author/2168000538 title="Chinese Academy Of Sciences">Yi Chang</a></td><td>Mesa, Data Mining, Computer Science</td></tr><tr><td style=text-align:right>21</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/dab10c50dc668cd8560df444ff3a4227-Abstract.html>Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev</a></td><td><a href=https://academic.microsoft.com/author/2896859019 title="Singapore University Of Technology And Design">Xiao Wang</a>, <a href=https://academic.microsoft.com/author/2265506623 title="University Of Texas At Austin">Qi Lei</a>, <a href=https://academic.microsoft.com/author/34265459 title="Singapore University Of Technology And Design">Ioannis Panageas</a></td><td>Langevin Dynamics, Sobolev Space, Geodesic, Manifold, Convergence, Mathematical Analysis, Mathematics</td></tr><tr><td style=text-align:right>22</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/5938b4d054136e5d59ada6ec9c295d7a-Abstract.html>Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent</a></td><td><a href=https://academic.microsoft.com/author/2111231380 title="National Technical University Of Athens">Dimitris Fotakis</a>, <a href=https://academic.microsoft.com/author/59040511 title="University Of Texas At Austin">Thanasis Lianeas</a>, <a href=https://academic.microsoft.com/author/2585738440 title="Singapore University Of Technology And Design">Georgios Piliouras</a>, <a href=https://academic.microsoft.com/author/2781542527 title="National Technical University Of Athens">Stratis Skoulakis</a></td><td>Gradient Descent, Dimensionality Reduction, Mathematical Optimization, Computer Science, Online Learning</td></tr><tr><td style=text-align:right>23</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/3f1656d9668dffcf8119e3ecff873558-Abstract.html>On Testing of Samplers</a></td><td><a href=https://academic.microsoft.com/author/2037223565 title="National University Of Singapore">Kuldeep S Meel</a>, <a href=https://academic.microsoft.com/author/2965067459 title="National University Of Singapore">Yash Pralhad Pote</a>, <a href=https://academic.microsoft.com/author/2600580662 title="Ohio State University">Sourav Chakraborty</a></td><td></td></tr><tr><td style=text-align:right>24</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/68d3743587f71fbaa5062152985aff40-Abstract.html>Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples</a></td><td><a href=https://academic.microsoft.com/author/2571812065 title="National University Of Singapore">Jay Nandy</a>, <a href=https://academic.microsoft.com/author/2123778117 title="National University Of Singapore">Wynne Hsu</a>, <a href=https://academic.microsoft.com/author/2159408573 title="National University Of Singapore">Mong Li Lee</a></td><td>Mathematical Optimization, Computer Science</td></tr><tr><td style=text-align:right>25</td><td><a href=https://papers.nips.cc/paper/2020/hash/0ed9422357395a0d4879191c66f4faa2-Abstract.html>No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix</a></td><td><a href=https://academic.microsoft.com/author/2982312499 title="Columbia University">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href=https://academic.microsoft.com/author/2555699898 title="Columbia University">Lampros Flokas</a>, <a href=https://academic.microsoft.com/author/59040511 title="University Of Texas At Austin">Thanasis Lianeas</a>, <a href=https://academic.microsoft.com/author/200977083 title="Centre National De La Recherche Scientifique">Panayotis Mertikopoulos</a>, <a href=https://academic.microsoft.com/author/2585738440 title="Singapore University Of Technology And Design">Georgios Piliouras</a></td><td>Regret, Nash Equilibrium, Mathematical Economics, Economics</td></tr><tr><td style=text-align:right>26</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/6f3a770e5af1fd4cadc5f004b81e1040-Abstract.html>Optimal Query Complexity of Secure Stochastic Convex Optimization</a></td><td><a href=https://academic.microsoft.com/author/3101413053>Wei Tang</a>, <a href=https://academic.microsoft.com/author/2123843302 title="Washington University In St Louis">Chien-Ju Ho</a>, <a href=https://academic.microsoft.com/author/2201441985 title="Nanyang Technological University">Yang Liu</a></td><td>Convex Optimization, Mathematical Optimization, Computer Science</td></tr><tr><td style=text-align:right>27</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/201d7288b4c18a679e48b31c72c30ded-Abstract.html>Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization</a></td><td><a href=https://academic.microsoft.com/author/2105799095 title="Nanyang Technological University">Haoliang Li</a>, <a href=https://academic.microsoft.com/author/3086043215 title="Nanyang Technological University">Yufei Wang</a>, <a href=https://academic.microsoft.com/author/2231543299 title="Nanyang Technological University">Renjie Wan</a>, <a href=https://academic.microsoft.com/author/2134010418 title="City University Of Hong Kong">Shiqi Wang</a>, <a href=https://academic.microsoft.com/author/3088560770 title="City University Of Hong Kong">Tie-Qiang Li</a>, <a href=https://academic.microsoft.com/author/2117310729 title="Nanyang Technological University">Alex C. Kot</a></td><td>Medical Imaging, Regularization, Pattern Recognition, Computer Science, Artificial Intelligence, Linear Dependency</td></tr><tr><td style=text-align:right>28</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/23ad3e314e2a2b43b4c720507cec0723-Abstract.html>Cross-Scale Internal Graph Neural Network for Image Super-Resolution</a></td><td><a href=https://academic.microsoft.com/author/2097820858 title="Nanyang Technological University">Shangchen Zhou</a>, <a href=https://academic.microsoft.com/author/2553700666 title=Sensetime>Jiawei Zhang</a>, <a href=https://academic.microsoft.com/author/2079150322 title="Harbin Institute Of Technology">Wangmeng Zuo</a>, <a href=https://academic.microsoft.com/author/3053927530 title="Nanyang Technological University">Chen Change Loy</a></td><td>Algorithm, Computer Science, Cross Scale, Graph Neural Networks, Superresolution</td></tr><tr><td style=text-align:right>29</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/add5aebfcb33a2206b6497d53bc4f309-Abstract.html>Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation</a></td><td><a href=https://academic.microsoft.com/author/2926024243 title="Northwestern Polytechnical University">Jianyuan Wang</a>, <a href=https://academic.microsoft.com/author/2752350893 title="Australian National University">Yiran Zhong</a>, <a href=https://academic.microsoft.com/author/2474928823 title="Northwestern Polytechnical University">Yuchao Dai</a>, <a href=https://academic.microsoft.com/author/2324159050 title="Australian National University">Kaihao Zhang</a>, <a href=https://academic.microsoft.com/author/2752580821 title="National University Of Singapore">Pan Ji</a>, <a href=https://academic.microsoft.com/author/2925516663 title="Australian National University">Hongdong Li</a></td><td>Invariant, Algorithm, Computer Science, Optical Flow Estimation</td></tr><tr><td style=text-align:right>30</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/1943102704f8f8f3302c2b730728e023-Abstract.html>Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation</a></td><td><a href=https://academic.microsoft.com/author/2969783607 title="National University Of Singapore">Jianfeng Zhang</a>, <a href=https://academic.microsoft.com/author/2560297500 title="National University Of Singapore">Xuecheng Nie</a>, <a href=https://academic.microsoft.com/author/3081085593 title="National University Of Singapore">Jiashi Feng</a></td><td>Inference, Pose, Machine Learning, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>31</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/a8acc28734d4fe90ea24353d901ae678-Abstract.html>Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning</a></td><td><a href=https://academic.microsoft.com/author/2275249846 title="Indian Institute Of Science">Arnab Bhattacharyya</a>, <a href=https://academic.microsoft.com/author/3006254182 title="National University Of Singapore">Sutanu Gayen</a>, <a href=https://academic.microsoft.com/author/2037223565 title="National University Of Singapore">Kuldeep S Meel</a>, <a href=https://academic.microsoft.com/author/406918582 title="University Of Nebraska Lincoln">N. V. Vinodchandran</a></td><td>Mathematical Analysis, Mathematics, Distance Approximation, High Dimensional</td></tr><tr><td style=text-align:right>32</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/dd45045f8c68db9f54e70c67048d32e8-Abstract.html>The Generalized Lasso with Nonlinear Observations and Generative Priors</a></td><td><a href=https://academic.microsoft.com/author/2686229780 title="National University Of Singapore">Zhaoqiang Liu</a>, <a href=https://academic.microsoft.com/author/2158423587 title="National University Of Singapore">Jonathan Scarlett</a></td><td>Lasso, Prior Probability, Nonlinear System, Generative Grammar, Algorithm, Computer Science</td></tr><tr><td style=text-align:right>33</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/5a751d6a0b6ef05cfe51b86e5d1458e6-Abstract.html>Improving Generalization in Reinforcement Learning with Mixture Regularization</a></td><td><a href=https://academic.microsoft.com/author/3093845801>Kaixin Wang</a>, <a href=https://academic.microsoft.com/author/2902440875 title="National University Of Singapore">Bingyi Kang</a>, <a href=https://academic.microsoft.com/author/3094098241>Jie Shao</a>, <a href=https://academic.microsoft.com/author/3081085593 title="National University Of Singapore">Jiashi Feng</a></td><td>Reinforcement Learning, Regularization, Artificial Intelligence, Computer Science</td></tr><tr><td style=text-align:right>34</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/4ee78d4122ef8503fe01cdad3e9ea4ee-Abstract.html>Correlation Robust Influence Maximization</a></td><td><a href=https://academic.microsoft.com/author/2162363770 title="National University Of Singapore">Louis Chen</a>, <a href=https://academic.microsoft.com/author/2222083040 title="Singapore University Of Technology And Design">Divya Padmanabhan</a>, <a href=https://academic.microsoft.com/author/3097610427>Chee Chin Lim</a>, <a href=https://academic.microsoft.com/author/2166753682 title="Singapore University Of Technology And Design">Karthik Natarajan</a></td><td>Maximization, Correlation, Mathematical Optimization, Mathematics</td></tr><tr><td style=text-align:right>35</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/2bba9f4124283edd644799e0cecd45ca-Abstract.html>Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization</a></td><td><a href=https://academic.microsoft.com/author/3103641893 title="National University Of Singapore">Sreejith Balakrishnan</a>, <a href=https://academic.microsoft.com/author/2540213700 title="National University Of Singapore">Quoc Phong Nguyen</a>, <a href=https://academic.microsoft.com/author/2133261218 title="National University Of Singapore">Bryan Kian Hsiang Low</a>, <a href=https://academic.microsoft.com/author/2808235949 title="National University Of Singapore">Harold Soh</a></td><td>Bayesian Optimization, Artificial Intelligence, Computer Science, Inverse Reinforcement Learning</td></tr><tr><td style=text-align:right>36</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/0baf163c24ed14b515aaf57a9de5501c-Abstract.html>Taming Discrete Integration via the Boon of Dimensionality</a></td><td><a href=https://academic.microsoft.com/author/2574427182 title="Rice University">Jeffrey M. Dudek</a>, <a href=https://academic.microsoft.com/author/2126493327 title="Open University Of Israel">Dror Fried</a>, <a href=https://academic.microsoft.com/author/2037223565 title="National University Of Singapore">Kuldeep S. Meel</a></td><td>Curse Of Dimensionality, Theoretical Computer Science, Computer Science</td></tr><tr><td style=text-align:right>37</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/cffb6e2288a630c2a787a64ccc67097c-Abstract.html>Digraph Inception Convolutional Networks</a></td><td><a href=https://academic.microsoft.com/author/3004890614 title="National University Of Singapore">Zekun Tong</a>, <a href=https://academic.microsoft.com/author/2230258979 title="Xidian University">Yuxuan Liang</a>, <a href=https://academic.microsoft.com/author/3023737760>Changsheng Sun</a>, <a href=https://academic.microsoft.com/author/3048685624 title="National University Of Singapore">Xinke Li</a>, <a href=https://academic.microsoft.com/author/3004965433>David Rosenblum</a>, <a href=https://academic.microsoft.com/author/2097320922 title="National University Of Singapore">Andrew Lim</a></td><td>Digraph, Discrete Mathematics, Computer Science</td></tr><tr><td style=text-align:right>38</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/f3f27a324736617f20abbf2ffd806f6d-Abstract.html>Towards Theoretically Understanding Why Sgd Generalizes Better Than Adam in Deep Learning</a></td><td><a href=https://academic.microsoft.com/author/2890817041 title="National University Of Singapore">Pan Zhou</a>, <a href=https://academic.microsoft.com/author/2170351238 title="National University Of Singapore">Jiashi Feng</a>, <a href=https://academic.microsoft.com/author/3092199891 title="Salesforce Com">Chao Ma</a>, <a href=https://academic.microsoft.com/author/2095665791 title="Salesforce Com">Caiming Xiong</a>, <a href=https://academic.microsoft.com/author/108406206 title="Singapore Management University">Steven Chu Hong Hoi</a>, <a href=https://academic.microsoft.com/author/3105676971>Weinan E</a></td><td>Deep Learning, Cognitive Science, Computer Science, Artificial Intelligence</td></tr><tr><td style=text-align:right>39</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html>Balanced Meta-Softmax for Long-Tailed Visual Recognition</a></td><td><a href=https://academic.microsoft.com/author/3100326700>Ren Jiawei</a>, <a href=https://academic.microsoft.com/author/3039935551 title=Sensetime>Cunjun Yu</a>, <a href=https://academic.microsoft.com/author/3043828928>shunan sheng</a>, <a href=https://academic.microsoft.com/author/2947621730 title="National University Of Singapore">Xiao Ma</a>, <a href=https://academic.microsoft.com/author/3040557127 title=Sensetime>Haiyu Zhao</a>, <a href=https://academic.microsoft.com/author/2114282903 title=Sensetime>Shuai Yi</a>, <a href=https://academic.microsoft.com/author/2141739595 title="The Chinese University Of Hong Kong">hongsheng Li</a></td><td>Softmax Function, Speech Recognition, Computer Science, Visual Recognition</td></tr><tr><td style=text-align:right>40</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/66de6afdfb5fb3c21d0e3b5c3226bf00-Abstract.html>Chaos, Extremism and Optimism: Volume Analysis of Learning in Games</a></td><td><a href=https://academic.microsoft.com/author/2153022342 title="Singapore University Of Technology And Design">Yun Kuen Cheung</a>, <a href=https://academic.microsoft.com/author/2585738440 title="Singapore University Of Technology And Design">Georgios Piliouras</a></td><td>Optimism, Social Psychology, Psychology, Volume Analysis</td></tr><tr><td style=text-align:right>41</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/cdf6581cb7aca4b7e19ef136c6e601a5-Abstract.html>Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting</a></td><td><a href=https://academic.microsoft.com/author/3083293699>Defu Cao</a>, <a href=https://academic.microsoft.com/author/3094355217 title=Microsoft>Yujing Wang</a>, <a href=https://academic.microsoft.com/author/2096822052 title="National University Of Singapore">Juanyong Duan</a>, <a href=https://academic.microsoft.com/author/2776066402 title="University Of Zurich">Ce Zhang</a>, <a href=https://academic.microsoft.com/author/3101960781>Xia Zhu</a>, <a href=https://academic.microsoft.com/author/2948216002 title=Microsoft>Congrui Huang</a>, <a href=https://academic.microsoft.com/author/2646469050 title="Peking University">Yunhai Tong</a>, <a href=https://academic.microsoft.com/author/2948627076 title=Microsoft>Bixiong Xu</a>, <a href=https://academic.microsoft.com/author/2990551768 title=Microsoft>Jing Bai</a>, <a href=https://academic.microsoft.com/author/2948319301 title=Microsoft>Jie Tong</a>, <a href=https://academic.microsoft.com/author/3000518790 title=Microsoft>Qi Zhang</a></td><td>Time Series, Multivariate Statistics, Pattern Recognition, Computer Science, Artificial Intelligence, Graph Neural Networks</td></tr><tr><td style=text-align:right>42</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/a914ecef9c12ffdb9bede64bb703d877-Abstract.html>Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning</a></td><td><a href=https://academic.microsoft.com/author/2963245002 title="Nanyang Technological University">Jianda Chen</a>, <a href=https://academic.microsoft.com/author/2304513243 title="Nanyang Technological University">Shangyu Chen</a>, <a href=https://academic.microsoft.com/author/2120836466 title="Nanyang Technological University">Sinno Jialin Pan</a></td><td>Reinforcement Learning, Channel, Pruning, Distributed Computing, Computer Science</td></tr><tr><td style=text-align:right>43</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/13f320e7b5ead1024ac95c3b208610db-Abstract.html>Self-Supervised Relationship Probing</a></td><td><a href=https://academic.microsoft.com/author/2634692963 title="Nanyang Technological University">Jiuxiang Gu</a>, <a href=https://academic.microsoft.com/author/2338033149 title="Adobe Systems">Jason Kuen</a>, <a href=https://academic.microsoft.com/author/1208744602 title="Qatar Foundation">Shafiq Joty</a>, <a href=https://academic.microsoft.com/author/2093782331 title="Monash University">Jianfei Cai</a>, <a href=https://academic.microsoft.com/author/1996029320 title="Adobe Systems">Vlad Morariu</a>, <a href=https://academic.microsoft.com/author/2304631232 title="Adobe Systems">Handong Zhao</a>, <a href=https://academic.microsoft.com/author/3013108186 title="Adobe Systems">Tong Sun</a></td><td>Machine Learning, Psychology, Artificial Intelligence</td></tr><tr><td style=text-align:right>44</td><td><a href=https://proceedings.neurips.cc/paper/2020/hash/1e591403ff232de0f0f139ac51d99295-Abstract.html>Partially View-aligned Clustering</a></td><td><a href=https://academic.microsoft.com/author/2892816713 title="Sichuan University">Zhenyu Huang</a>, <a href=https://academic.microsoft.com/author/3087012719>Peng Hu</a>, <a href=https://academic.microsoft.com/author/2170372657 title="Institute Of High Performance Computing Singapore">Joey Tianyi Zhou</a>, <a href=https://academic.microsoft.com/author/2194393727 title="Sichuan University">Jiancheng Lv</a>, <a href=https://academic.microsoft.com/author/2674279261 title="Sichuan University">Xi Peng</a></td><td>Cluster Analysis, Pattern Recognition, Computer Science, Artificial Intelligence</td></tr></tbody></table><p>There is no particular order of note. The list was ranked by early citations, which is as good as random for now. Data was
obtained from the pretty awesome <a href=https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/>Microsoft Academic Graph</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://news.machinelearning.sg/tags/neurips>NeurIPS</a></li><li><a href=https://news.machinelearning.sg/tags/deep-learning>Deep Learning</a></li><li><a href=https://news.machinelearning.sg/tags/singapore>Singapore</a></li><li><a href=https://news.machinelearning.sg/tags/machine-learning>Machine Learning</a></li><li><a href=https://news.machinelearning.sg/tags/neuroscience>Neuroscience</a></li><li><a href=https://news.machinelearning.sg/tags/conferences>Conferences</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on twitter" href="https://twitter.com/intent/tweet/?text=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f&hashtags=NeurIPS%2cDeepLearning%2cSingapore%2cMachineLearning%2cNeuroscience%2cConferences"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f&title=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year&summary=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year&source=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f&title=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on whatsapp" href="https://api.whatsapp.com/send?text=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year%20-%20https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share NeurIPS2020 - Singapore's Entries at the Top Machine Learning Conference This Year on telegram" href="https://telegram.me/share/url?text=NeurIPS2020%20-%20Singapore%27s%20Entries%20at%20the%20Top%20Machine%20Learning%20Conference%20This%20Year&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2fneurips2020_singapores_entries_at_the_top_machine_learning_conference_this_year%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2020 <a href=https://news.machinelearning.sg/>News @ machinelearning.sg</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=https://news.machinelearning.sg/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>