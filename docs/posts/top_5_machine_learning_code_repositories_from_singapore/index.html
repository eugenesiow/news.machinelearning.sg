<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Top 5 Machine Learning Code Repositories from Singapore | News @ machinelearning.sg</title>
<meta name=keywords content="Github,Deep Learning,Singapore,Machine Learning,Source Code,PyTorch,TensorFlow,Computer Vision,Natural Language Processing,Finance">
<meta name=description content="tl;dr We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of popular implementations of state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) models and even a high-frequency trading project. The ranking is decided based on the total stars (stargazer count) of the repositories.
 5. PyTorch Implementation of EfficientDet  Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).">
<meta name=author content="Eugene">
<link rel=canonical href=https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/>
<link href=https://news.machinelearning.sg/assets/css/stylesheet.min.d1ce48677bc3d2b81f6398ed4ae6ddf7262d885c01ffefc464636bbea61c0201.css integrity="sha256-0c5IZ3vD0rgfY5jtSubd9yYtiFwB/+/EZGNrvqYcAgE=" rel="preload stylesheet" as=style>
<link rel=icon href=https://news.machinelearning.sg/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://news.machinelearning.sg/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://news.machinelearning.sg/favicon-32x32.png>
<link rel=apple-touch-icon href=https://news.machinelearning.sg/apple-touch-icon.png>
<link rel=mask-icon href=https://news.machinelearning.sg/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.88.1">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-185405110-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<meta property="og:title" content="Top 5 Machine Learning Code Repositories from Singapore">
<meta property="og:description" content="tl;dr We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of popular implementations of state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) models and even a high-frequency trading project. The ranking is decided based on the total stars (stargazer count) of the repositories.
 5. PyTorch Implementation of EfficientDet  Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).">
<meta property="og:type" content="article">
<meta property="og:url" content="https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/">
<meta property="og:image" content="https://news.machinelearning.sg/repo_efficientdet.gif"><meta property="article:published_time" content="2020-12-10T08:00:00+08:00">
<meta property="article:modified_time" content="2020-12-10T08:00:00+08:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://news.machinelearning.sg/repo_efficientdet.gif">
<meta name=twitter:title content="Top 5 Machine Learning Code Repositories from Singapore">
<meta name=twitter:description content="tl;dr We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of popular implementations of state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) models and even a high-frequency trading project. The ranking is decided based on the total stars (stargazer count) of the repositories.
 5. PyTorch Implementation of EfficientDet  Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Top 5 Machine Learning Code Repositories from Singapore","name":"Top 5 Machine Learning Code Repositories from Singapore","description":"tl;dr We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of popular implementations of state-of-the-art Computer Vision (CV) …","keywords":["Github","Deep Learning","Singapore","Machine Learning","Source Code","PyTorch","TensorFlow","Computer Vision","Natural Language Processing","Finance"],"articleBody":" tl;dr We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of popular implementations of state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) models and even a high-frequency trading project. The ranking is decided based on the total stars (stargazer count) of the repositories.\n 5. PyTorch Implementation of EfficientDet  Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).   A PyTorch implementation of the 2019 Computer Vision paper EfficientDet: Scalable and Efficient Object Detection from Google Brain. The official implementation by Google Brain is in TensorFlow.\n         Repository toandaominh1997/EfficientDet.Pytorch   License MIT   Author Đào Minh Toàn (toandaominh1997)   Vocation Data Scientist at VinID       Language Stars Forks Watchers Open Issues     Python 1,337 300 44 112    4. Object Detection: YOLO3  Object bounding boxes on video footage as predicted by YOLO3. Retrieved from the official YOLO site.   A Computer Vision repository with code for training and evaluation of a YOLO3 model for the Object Detection task. YOLO, You Only Look Once, is a state-of-the-art, real-time object detection model. Its claim to fame is its extremely fast and accurate and you can trade-off speed and accuracy without re-training by changing the model size. Multi-GPU training is also implemented.\n         Repository experiencor/keras-yolo3   License MIT   Author Huynh Ngoc Anh (experiencor)   Vocation Machine Learning Engineer at Grab       Language Stars Forks Watchers Open Issues     Python 1,362 753 54 217    3. Chinese Named Entity Recognition and Relation Extraction  Visualization of 3x3, 7x7 and 15x15 receptive fields produced by 1, 2 and 4 dilated convolutions by the IDCNN model.   An NLP repository including state-of-art deep learning methods for various tasks in chinese/mandarin language (中文): named entity recognition (NER/实体识别), relation extraction (RE/关系提取) and word segmentation.\n         Repository crownpku/Information-Extraction-Chinese   License Not Specified   Author Wang Guan (crownpku)   Vocation Senior Data Scientist, VP at Swiss Re       Language Stars Forks Watchers Open Issues     Python 1,692 748 90 102    2. High-frequency Trading Model using the Interactive Brokers API  Demo of setting up the model using docker-compose. Retrieved from Github.   A high-frequency trading model using Interactive Brokers API with pairs and mean-reversion in Python. It was last updated with v3.0 in June 2019. The author describes the model as utilizing statistical arbitrage incorporating these methodologies:\n Bootstrapping the model with historical data to derive usable strategy parameters Resampling inhomogeneous time series to homogeneous time series Selection of highly-correlated tradable pair The ability to short one instrument and long the other. Using volatility ratio to detect up or down trend. Fair valuation of security using beta, or the mean over some past interval. One pandas DataFrame to store historical prices           Repository jamesmawm/High-Frequency-Trading-Model-with-IB   License MIT   Author James Ma (jamesmawm)   Vocation Full-stack software engineer and author of Mastering Python for Finance.       Language Stars Forks Watchers Open Issues     Python 1,734 525 231 7    1. DeepLab v3+ model in PyTorch  Some results of the deep labelling model on various datasets. Retrieved from Github.   A computer vision repository which started with an early PyTorch implementation (circa 2018) of DeepLab-V3-Plus (in PyTorch 0.4.1). DeepLab is a series of image semantic segmentation models whose latest version, v3+, is state-of-art on the semantic segmentation task. It can use Modified Aligned Xception and ResNet as backbone. The authors train DeepLab V3 Plus using Pascal VOC 2012, SBD and Cityscapes datasets. Pre-trained models on ResNet, MobileNet and DRN are provided.\n         Repository jfzhang95/pytorch-deeplab-xception   License MIT   Author Jianfeng Zhang (jfzhang95)   Vocation PhD Student at NUS       Language Stars Forks Watchers Open Issues     Python 2,057 634 47 95    More ML repositories Visit machinelearning.sg to view a full list of ML repositories from Singapore.\n","wordCount":"587","inLanguage":"en","image":"https://news.machinelearning.sg/repo_efficientdet.gif","datePublished":"2020-12-10T08:00:00+08:00","dateModified":"2020-12-10T08:00:00+08:00","author":{"@type":"Person","name":"Eugene"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/"},"publisher":{"@type":"Organization","name":"News @ machinelearning.sg","logo":{"@type":"ImageObject","url":"https://news.machinelearning.sg/favicon.ico"}}}</script>
<script async data-id=defa0fb0-3f27-4afe-b567-4f57d47c86e9 src=https://tinyads.io/e></script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<noscript>
<style type=text/css>.theme-toggle,.top-link{display:none}</style>
</noscript>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://news.machinelearning.sg/ accesskey=h>News
</a>
<span class=logo-switches>
<span class=theme-toggle>
<a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</a>
</span>
<span class=lang-switch>
<ul>
<li>
<a href=https://machinelearning.sg>
machinelearning.sg
</a>
</li>
</ul>
</span>
</span>
</div>
<ul class=menu id=menu onscroll=menu_on_scroll()>
<li>
<a href=https://news.machinelearning.sg/about/>
<span>
About
</span>
</a>
</li>
<li>
<a href=https://news.machinelearning.sg/archives/>
<span>
Archive
</span>
</a>
</li>
<li>
<a href=https://news.machinelearning.sg/tags/>
<span>
Tags
</span>
</a>
</li></ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Top 5 Machine Learning Code Repositories from Singapore
</h1>
<div class=post-meta>
December 10, 2020&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Eugene
</div>
</header>
<figure class=entry-cover>
<img srcset="https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/repo_efficientdet_hua17d428776269fb009edf0ab01d7c419_163984_360x0_resize_box.gif 360w ,https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/repo_efficientdet_hua17d428776269fb009edf0ab01d7c419_163984_480x0_resize_box.gif 480w ,https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/repo_efficientdet_hua17d428776269fb009edf0ab01d7c419_163984_720x0_resize_box.gif 720w ,https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/repo_efficientdet.gif 910w" sizes="(min-width: 768px) 720px, 100vw" src=https://news.machinelearning.sg/posts/top_5_machine_learning_code_repositories_from_singapore/repo_efficientdet.gif alt="Object bounding boxes on video footage as predicted by EfficientDet, a family of scalable and efficient object detectors.">
<p>Object bounding boxes on video footage as predicted by EfficientDet, a family of scalable and efficient object detectors.</p>
</figure>
<div class=toc>
<details>
<summary>
<div class=details accesskey=c>Table of Contents</div>
</summary>
<blockquote><ul><li>
<a href=#5-pytorch-implementation-of-efficientdet aria-label="5. PyTorch Implementation of EfficientDet">5. PyTorch Implementation of EfficientDet</a><ul>
<ul>
<li>
<a href=# aria-label="Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).">Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).</a></li></ul>
</ul>
</li><li>
<a href=#4-object-detection-yolo3 aria-label="4. Object Detection: YOLO3">4. Object Detection: YOLO3</a><ul>
<ul>
<li>
<a href=# aria-label="Object bounding boxes on video footage as predicted by YOLO3. Retrieved from the official YOLO site.">Object bounding boxes on video footage as predicted by YOLO3. Retrieved from the official YOLO site.</a></li></ul>
</ul>
</li><li>
<a href=#3-chinese-named-entity-recognition-and-relation-extraction aria-label="3. Chinese Named Entity Recognition and Relation Extraction">3. Chinese Named Entity Recognition and Relation Extraction</a><ul>
<ul>
<li>
<a href=# aria-label="Visualization of 3x3, 7x7 and 15x15 receptive fields produced by 1, 2 and 4 dilated convolutions by the IDCNN model.">Visualization of 3x3, 7x7 and 15x15 receptive fields produced by 1, 2 and 4 dilated convolutions by the IDCNN model.</a></li></ul>
</ul>
</li><li>
<a href=#2-high-frequency-trading-model-using-the-interactive-brokers-api aria-label="2. High-frequency Trading Model using the Interactive Brokers API">2. High-frequency Trading Model using the Interactive Brokers API</a><ul>
<ul>
<li>
<a href=# aria-label="Demo of setting up the model using docker-compose. Retrieved from Github.">Demo of setting up the model using docker-compose. Retrieved from Github.</a></li></ul>
</ul>
</li><li>
<a href=#1-deeplab-v3-model-in-pytorch aria-label="1. DeepLab v3+ model in PyTorch">1. DeepLab v3+ model in PyTorch</a><ul>
<ul>
<li>
<a href=# aria-label="Some results of the deep labelling model on various datasets. Retrieved from Github.">Some results of the deep labelling model on various datasets. Retrieved from Github.</a></li></ul>
</ul>
</li><li>
<a href=#more-ml-repositories aria-label="More ML repositories">More ML repositories</a></li></ul>
</blockquote>
</details>
</div>
<div class=post-content>
<blockquote>
<p><strong>tl;dr</strong> We feature 5 of the top machine learning code repositories on Github from Singapore. The Top 5 is made up of
popular implementations of state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) models and
even a high-frequency trading project. The ranking is decided based on the total stars (stargazer count) of the
repositories.</p>
</blockquote>
<h2 id=5-pytorch-implementation-of-efficientdet>5. PyTorch Implementation of EfficientDet<a hidden class=anchor aria-hidden=true href=#5-pytorch-implementation-of-efficientdet>#</a></h2>
<figure><img src=repo_efficientdet_archi.png><figcaption>
<h4>Architecture of EfficientDet including a weighted bi-directional feature pyramid network (BiFPN).</h4>
</figcaption>
</figure>
<p>A PyTorch implementation of the 2019 <strong>Computer Vision</strong> paper <a href=https://arxiv.org/abs/1911.09070>EfficientDet: Scalable and Efficient Object Detection</a> from Google Brain.
The <a href=https://github.com/google/automl/tree/master/efficientdet>official implementation</a> by Google Brain is in TensorFlow.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Repository</td>
<td><a href=https://github.com/toandaominh1997/EfficientDet.Pytorch>toandaominh1997/EfficientDet.Pytorch</a></td>
</tr>
<tr>
<td>License</td>
<td><a href=https://github.com/toandaominh1997/EfficientDet.Pytorch/blob/master/LICENSE>MIT</a></td>
</tr>
<tr>
<td>Author</td>
<td><a href=https://twitter.com/toandaominh1997>Đào Minh Toàn</a> (<a href=https://github.com/toandaominh1997>toandaominh1997</a>)</td>
</tr>
<tr>
<td>Vocation</td>
<td><a href=https://www.linkedin.com/in/toandaominh1997>Data Scientist</a> at <a href=https://medium.com/vinid>VinID</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Language</th>
<th>Stars</th>
<th>Forks</th>
<th>Watchers</th>
<th>Open Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>1,337</td>
<td>300</td>
<td>44</td>
<td>112</td>
</tr>
</tbody>
</table>
<h2 id=4-object-detection-yolo3>4. Object Detection: YOLO3<a hidden class=anchor aria-hidden=true href=#4-object-detection-yolo3>#</a></h2>
<figure><img src=repo_yolo3.png><figcaption>
<h4>Object bounding boxes on video footage as predicted by YOLO3. Retrieved from the official YOLO site.</h4>
</figcaption>
</figure>
<p>A <strong>Computer Vision</strong> repository with code for training and evaluation of a YOLO3 model for the <strong>Object Detection</strong> task.
<a href=https://pjreddie.com/darknet/yolo/>YOLO</a>, You Only Look Once, is a state-of-the-art, real-time object detection model.
Its claim to fame is its extremely fast and accurate and you can trade-off speed and accuracy without re-training
by changing the model size. Multi-GPU training is also implemented.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Repository</td>
<td><a href=https://github.com/experiencor/keras-yolo3>experiencor/keras-yolo3</a></td>
</tr>
<tr>
<td>License</td>
<td><a href=https://github.com/experiencor/keras-yolo3/blob/master/LICENSE>MIT</a></td>
</tr>
<tr>
<td>Author</td>
<td><a href=https://experiencor.github.io/>Huynh Ngoc Anh</a> (<a href=https://github.com/experiencor>experiencor</a>)</td>
</tr>
<tr>
<td>Vocation</td>
<td><a href=https://sg.linkedin.com/in/ngoca>Machine Learning Engineer</a> at <a href=https://engineering.grab.com/>Grab</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Language</th>
<th>Stars</th>
<th>Forks</th>
<th>Watchers</th>
<th>Open Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>1,362</td>
<td>753</td>
<td>54</td>
<td>217</td>
</tr>
</tbody>
</table>
<h2 id=3-chinese-named-entity-recognition-and-relation-extraction>3. Chinese Named Entity Recognition and Relation Extraction<a hidden class=anchor aria-hidden=true href=#3-chinese-named-entity-recognition-and-relation-extraction>#</a></h2>
<figure><img src=repo_information_extraction_chinese.jfif><figcaption>
<h4>Visualization of 3x3, 7x7 and 15x15 receptive fields produced by 1, 2 and 4 dilated convolutions by the IDCNN model.</h4>
</figcaption>
</figure>
<p>An <strong>NLP</strong> repository including state-of-art deep learning methods for various tasks in chinese/mandarin language (中文):
named entity recognition (<strong>NER</strong>/实体识别), relation extraction (<strong>RE</strong>/关系提取) and word segmentation.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Repository</td>
<td><a href=https://github.com/crownpku/Information-Extraction-Chinese>crownpku/Information-Extraction-Chinese</a></td>
</tr>
<tr>
<td>License</td>
<td>Not Specified</td>
</tr>
<tr>
<td>Author</td>
<td><a href=http://www.crownpku.com/>Wang Guan</a> (<a href=https://github.com/crownpku>crownpku</a>)</td>
</tr>
<tr>
<td>Vocation</td>
<td><a href=https://www.linkedin.com/in/crownpku/>Senior Data Scientist, VP</a> at <a href=https://www.linkedin.com/company/swiss-re/>Swiss Re</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Language</th>
<th>Stars</th>
<th>Forks</th>
<th>Watchers</th>
<th>Open Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>1,692</td>
<td>748</td>
<td>90</td>
<td>102</td>
</tr>
</tbody>
</table>
<h2 id=2-high-frequency-trading-model-using-the-interactive-brokers-api>2. High-frequency Trading Model using the Interactive Brokers API<a hidden class=anchor aria-hidden=true href=#2-high-frequency-trading-model-using-the-interactive-brokers-api>#</a></h2>
<figure><img src=repo_high_frequency_trading.gif><figcaption>
<h4>Demo of setting up the model using docker-compose. Retrieved from Github.</h4>
</figcaption>
</figure>
<p>A high-frequency trading model using Interactive Brokers API with pairs and mean-reversion in Python.
It was last updated with v3.0 in June 2019.
The author describes the model as utilizing statistical arbitrage incorporating these methodologies:</p>
<ul>
<li>Bootstrapping the model with historical data to derive usable strategy parameters</li>
<li><strong>Resampling</strong> inhomogeneous time series to homogeneous time series</li>
<li>Selection of <strong>highly-correlated tradable pair</strong></li>
<li>The ability to short one instrument and long the other.</li>
<li>Using <strong>volatility ratio</strong> to detect up or down trend.</li>
<li>Fair valuation of security using <strong>beta</strong>, or the mean over some past interval.</li>
<li>One pandas DataFrame to store historical prices</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Repository</td>
<td><a href=https://github.com/jamesmawm/High-Frequency-Trading-Model-with-IB>jamesmawm/High-Frequency-Trading-Model-with-IB</a></td>
</tr>
<tr>
<td>License</td>
<td><a href=https://github.com/jamesmawm/High-Frequency-Trading-Model-with-IB/blob/master/LICENSE>MIT</a></td>
</tr>
<tr>
<td>Author</td>
<td><a href=https://linkedin.com/in/jamesmawm>James Ma</a> (<a href=https://github.com/jamesmawm>jamesmawm</a>)</td>
</tr>
<tr>
<td>Vocation</td>
<td>Full-stack software engineer and author of <code>Mastering Python for Finance</code>.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Language</th>
<th>Stars</th>
<th>Forks</th>
<th>Watchers</th>
<th>Open Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>1,734</td>
<td>525</td>
<td>231</td>
<td>7</td>
</tr>
</tbody>
</table>
<h2 id=1-deeplab-v3-model-in-pytorch>1. DeepLab v3+ model in PyTorch<a hidden class=anchor aria-hidden=true href=#1-deeplab-v3-model-in-pytorch>#</a></h2>
<figure><img src=repo_pytorch_deeplab.png><figcaption>
<h4>Some results of the deep labelling model on various datasets. Retrieved from Github.</h4>
</figcaption>
</figure>
<p>A computer vision repository which started with an early PyTorch implementation (circa 2018) of DeepLab-V3-Plus (in PyTorch 0.4.1).
DeepLab is a series of <strong>image semantic segmentation</strong> models whose latest version, v3+, is state-of-art on the semantic segmentation task.
It can use Modified Aligned Xception and ResNet as backbone.
The authors train DeepLab V3 Plus using Pascal VOC 2012, SBD and Cityscapes datasets. Pre-trained models on ResNet,
MobileNet and DRN are provided.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Repository</td>
<td><a href=https://github.com/jfzhang95/pytorch-deeplab-xception>jfzhang95/pytorch-deeplab-xception</a></td>
</tr>
<tr>
<td>License</td>
<td><a href=https://github.com/jfzhang95/pytorch-deeplab-xception/blob/master/LICENSE>MIT</a></td>
</tr>
<tr>
<td>Author</td>
<td><a href=http://jeff95.me/>Jianfeng Zhang</a> (<a href=https://github.com/jfzhang95>jfzhang95</a>)</td>
</tr>
<tr>
<td>Vocation</td>
<td>PhD Student at NUS</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Language</th>
<th>Stars</th>
<th>Forks</th>
<th>Watchers</th>
<th>Open Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>2,057</td>
<td>634</td>
<td>47</td>
<td>95</td>
</tr>
</tbody>
</table>
<h2 id=more-ml-repositories>More ML repositories<a hidden class=anchor aria-hidden=true href=#more-ml-repositories>#</a></h2>
<p>Visit <a href=https://machinelearning.sg/repo/>machinelearning.sg</a> to view a full list of ML repositories from Singapore.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://news.machinelearning.sg/tags/github>Github</a></li>
<li><a href=https://news.machinelearning.sg/tags/deep-learning>Deep Learning</a></li>
<li><a href=https://news.machinelearning.sg/tags/singapore>Singapore</a></li>
<li><a href=https://news.machinelearning.sg/tags/machine-learning>Machine Learning</a></li>
<li><a href=https://news.machinelearning.sg/tags/source-code>Source Code</a></li>
<li><a href=https://news.machinelearning.sg/tags/pytorch>PyTorch</a></li>
<li><a href=https://news.machinelearning.sg/tags/tensorflow>TensorFlow</a></li>
<li><a href=https://news.machinelearning.sg/tags/computer-vision>Computer Vision</a></li>
<li><a href=https://news.machinelearning.sg/tags/natural-language-processing>Natural Language Processing</a></li>
<li><a href=https://news.machinelearning.sg/tags/finance>Finance</a></li>
</ul>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on twitter" href="https://twitter.com/intent/tweet/?text=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f&hashtags=Github%2cDeepLearning%2cSingapore%2cMachineLearning%2cSourceCode%2cPyTorch%2cTensorFlow%2cComputerVision%2cNaturalLanguageProcessing%2cFinance"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f&title=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore&summary=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore&source=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f&title=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on whatsapp" href="https://api.whatsapp.com/send?text=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore%20-%20https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Top 5 Machine Learning Code Repositories from Singapore on telegram" href="https://telegram.me/share/url?text=Top%205%20Machine%20Learning%20Code%20Repositories%20from%20Singapore&url=https%3a%2f%2fnews.machinelearning.sg%2fposts%2ftop_5_machine_learning_code_repositories_from_singapore%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main><footer class=footer>
<span>&copy; 2021 <a href=https://news.machinelearning.sg/>News @ machinelearning.sg</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top" accesskey=g>
<button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg>
</button>
</a>
<script defer src=https://news.machinelearning.sg/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(a){a.preventDefault();var b=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(b)}']`).scrollIntoView({behavior:"smooth"})})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>